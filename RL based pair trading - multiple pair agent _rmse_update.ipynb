{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# Sheet"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"Sheet",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "sheet_delimiter":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "pip install kneed"
   ],
   "execution_count":64,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Requirement already satisfied: kneed in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (0.8.5)\r\n",
      "Requirement already satisfied: numpy>=1.14.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from kneed) (1.24.4)\r\n",
      "Requirement already satisfied: scipy>=1.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from kneed) (1.10.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"OqNR8qBgSZja8OlpWefoYI",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "pip install openpyxl"
   ],
   "execution_count":65,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Requirement already satisfied: openpyxl in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (3.1.5)\r\n",
      "Requirement already satisfied: et-xmlfile in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from openpyxl) (2.0.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"XUDcjyQe2BBBhi4xqGwN7c",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import torch"
   ],
   "execution_count":66,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"hs7o5W3KFddgkUbS93t7Wa",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from collections import deque\n",
    "import random\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple, deque\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import euclidean"
   ],
   "execution_count":67,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"9PPUdmkbRq5K3aZefIg9Bu",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Part 1: Data Preparation \n",
    "### Adjust the bond prices to mitigate the impact of the benchmark bond roll."
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"FxbEU0b1iwFkCFcDStcftK",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "tr_dm = pd.read_excel('GENERIC BOND PRICE.xlsx', sheet_name='DM_PRICE')\n",
    "tr_dm.Dates = pd.to_datetime(tr_dm.Dates)\n",
    "tr_dm = tr_dm.set_index('Dates')"
   ],
   "execution_count":68,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"na8Z7HraSCUpsgtAhiH9El",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def calculate_dirty_price(clean_price, coupon, days_since_last_coupon):\n",
    "    daily_coupon = coupon \/ 365  \n",
    "    accrued_interest = daily_coupon * days_since_last_coupon\n",
    "    return clean_price + accrued_interest\n",
    "\n",
    "def calculate_days_since_last_coupon(date, last_coupon_date):\n",
    "    return (date - last_coupon_date).days\n",
    "\n",
    "def find_first_coupon_date(coupon_series):\n",
    "    coupon_changes = coupon_series.diff().dropna()\n",
    "    if len(coupon_changes) > 0:\n",
    "        first_change_date = coupon_changes.index[0]\n",
    "        return first_change_date - pd.Timedelta(days=180)  # All coupon paid 6 months before the change\n",
    "    else:\n",
    "        return coupon_series.index[0] \n",
    "    "
   ],
   "execution_count":69,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"qCpLGNyRVbpXvM2HxK3bzl",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "dirty_price_series = {}\n",
    "for column in tr_dm.columns:\n",
    "    if column.endswith('Govt'):\n",
    "        clean_price_series = tr_dm[column]\n",
    "        coupon_series = tr_dm[f\"{column} CPN\"]\n",
    "\n",
    "        first_coupon_date = find_first_coupon_date(coupon_series)\n",
    "        last_coupon_date = first_coupon_date\n",
    "        current_coupon = coupon_series.iloc[0]\n",
    "        \n",
    "        dirty_prices = []\n",
    "        \n",
    "        for date, clean_price in clean_price_series.items():\n",
    "            if coupon_series[date] != current_coupon:\n",
    "                last_coupon_date = date - pd.Timedelta(days=180)\n",
    "                current_coupon = coupon_series[date]\n",
    "            \n",
    "            days_since_last_coupon = calculate_days_since_last_coupon(date, last_coupon_date)\n",
    "            \n",
    "            dirty_price = calculate_dirty_price(clean_price, current_coupon, days_since_last_coupon)\n",
    "            dirty_prices.append(dirty_price)\n",
    "\n",
    "            if days_since_last_coupon >= 180:\n",
    "                last_coupon_date = date\n",
    "\n",
    "        tr_dm[f\"{column}_Dirty\"] = pd.Series(dirty_prices, index=clean_price_series.index)"
   ],
   "execution_count":70,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"I9Td6deyEsn0KKhefI4Gkm",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "for bond_col in tr_dm.columns:\n",
    "    if bond_col.endswith('Dirty'): \n",
    "        coupon_col = bond_col.replace('Govt_Dirty', 'Govt CPN')\n",
    "        bond_col = bond_col.replace('_Dirty','')\n",
    "        \n",
    "        tr_dm[f\"{bond_col} Adjusted\"] = tr_dm[bond_col]\n",
    "        \n",
    "        coupon_changes = tr_dm[coupon_col].diff().fillna(0) != 0\n",
    "\n",
    "        for change_date in tr_dm.index[coupon_changes]:\n",
    "\n",
    "            price_on_change = tr_dm.loc[change_date, bond_col]\n",
    "            \n",
    "            previous_price = tr_dm.loc[tr_dm.index[tr_dm.index.get_loc(change_date) - 1], bond_col]\n",
    "            \n",
    "            price_diff = price_on_change - previous_price\n",
    "            \n",
    "            tr_dm.loc[change_date:, f\"{bond_col} Adjusted\"] -= price_diff\n",
    "\n",
    "        tr_dm[f\"{bond_col} Adjusted Return\"] = tr_dm[f\"{bond_col} Adjusted\"].pct_change()\n",
    "\n",
    "\n",
    "# col_adj = [i for i in tr_dm.columns if (i.endswith('Adjusted') or i.endswith('Adjusted Return'))]\n",
    "\n",
    "col_adj_price = [i for i in tr_dm.columns if i.endswith('Adjusted')]\n",
    "\n",
    "col_adj_return = [i for i in tr_dm.columns if i.endswith('Adjusted Return')]\n",
    "\n",
    "tr_dm_net = tr_dm[col_adj_return].fillna(0)\n",
    "\n",
    "tr_dm_net_price = tr_dm[col_adj_price].fillna(0)"
   ],
   "execution_count":71,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"s5S2f174w5nndoxNp8Ls5U",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Part 3: Identify Correlated Assets (Developed Market)\n",
    "### Step1 : PCA (cluster by the first principal component)"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"TuVft2K7E4OGuQ0C6RGmSQ",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from statsmodels.tsa.stattools import coint\n",
    "\n",
    "def test_cointegration_in_clusters(data, cluster_dict):\n",
    "\n",
    "    cointegrated_pairs = []\n",
    "    for cluster_num in cluster_dict:\n",
    "        asset_names = cluster_dict[cluster_num]\n",
    "        asset_names = [i.replace(' Return', '') for i in asset_names]\n",
    "        \n",
    "        # Loop through each pair of assets in the cluster\n",
    "        for i in range(len(asset_names)):\n",
    "            for j in range(i + 1, len(asset_names)):\n",
    "                asset1 = asset_names[i]\n",
    "                asset2 = asset_names[j]\n",
    "             \n",
    "                series1 = data[asset1]\n",
    "                series2 = data[asset2]\n",
    "                \n",
    "                # Perform the Engle-Granger cointegration test\n",
    "                coint_t, p_value, _ = coint(series1, series2)\n",
    "                \n",
    "                # set a higher significant level (0.2) to avoid missing potential relationship\n",
    "                if p_value < 0.2:  \n",
    "                    cointegrated_pairs.append([asset1,asset2])\n",
    "                else:\n",
    "                    pass\n",
    "                    # print(f\"  {asset1} and {asset2} are NOT cointegrated (p-value: {p_value:.4f})\")\n",
    "\n",
    "    return cointegrated_pairs\n"
   ],
   "execution_count":72,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"OAaLctWBqKuHggcbLfy7DD",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "def noncoherent_pair_cluster(data, data_price): # input: return data, price data\n",
    "    # Step 1: Cluster by Principal component 1\n",
    "    scaler = StandardScaler()\n",
    "    asset_returns = pd.DataFrame(scaler.fit_transform(data), columns= data.columns)\n",
    "\n",
    "\n",
    "    # Calculate the loadings of bond returns on PCs\n",
    "    K = 1\n",
    "    pca = PCA(n_components=K)\n",
    "    pca.fit(asset_returns)\n",
    "    loadings = pca.components_.T\n",
    "\n",
    "    wcss = []\n",
    "    for k in range(1, 10):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(loadings)\n",
    "        # Inertia: Sum of squared distances to closest cluster center\n",
    "        wcss.append(kmeans.inertia_)  \n",
    "        \n",
    "    # Use the KneeLocator to detect the elbow point\n",
    "    kneedle = KneeLocator(range(1, 10), wcss, S=1.0, curve='convex', direction='decreasing')\n",
    "\n",
    "    # Get the optimal number of clusters\n",
    "    optimal_clusters = kneedle.elbow\n",
    "\n",
    "\n",
    "    # Clustering in the principal component space and using K-means to cluster different govt bonds\n",
    "    kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(loadings)\n",
    "    asset_names = asset_returns.columns\n",
    "\n",
    "    cluster_dic = {}\n",
    "    for cluster in range(optimal_clusters):\n",
    "        cluster_assets = asset_names[clusters == cluster]\n",
    "        cluster_dic[cluster + 1] =cluster_assets\n",
    "\n",
    "\n",
    "    # Step 2: Find cointegration pairs\n",
    "    cointegrated_pairs = test_cointegration_in_clusters(data_price, cluster_dic)\n",
    "\n",
    "    # Step 3: Exclude pairs have similar PC2 and PC3\n",
    "    K = 3\n",
    "    pca = PCA(n_components=K)\n",
    "    pca.fit(asset_returns)\n",
    "    loadings = pca.components_.T\n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "\n",
    "    loadings_df = pd.DataFrame(loadings, columns = ['PC1','PC2','PC3'], index = data.columns)\n",
    "\n",
    "    pc2_diff_list = [abs(loadings_df.loc[f\"{i} Return\", 'PC2'] - loadings_df.loc[f\"{j} Return\", 'PC2']) for (i,j) in cointegrated_pairs]\n",
    "\n",
    "    threshold_pc2 = np.quantile(pc2_diff_list, 0.5)\n",
    "\n",
    "    coherent_pair = []\n",
    "    noncoherent_pair = []\n",
    "\n",
    "    for i in range(len(cointegrated_pairs)):\n",
    "        asset1 = cointegrated_pairs[i][0]\n",
    "        asset2 = cointegrated_pairs[i][1]\n",
    "\n",
    "        pc1_diff = abs(loadings_df.loc[f\"{asset1} Return\", 'PC1']  - loadings_df.loc[f\"{asset2} Return\", 'PC1'])\n",
    "        pc2_diff = abs(loadings_df.loc[f\"{asset1} Return\", 'PC2']  - loadings_df.loc[f\"{asset2} Return\", 'PC2'])\n",
    "\n",
    "        if pc2_diff < threshold_pc2:\n",
    "            coherent_pair.append((f'{asset1}', f'{asset2}'))\n",
    "            # print(asset1, asset2, pc1_diff, 'coherent')\n",
    "        else:\n",
    "            noncoherent_pair.append((f'{asset1}', f'{asset2}'))\n",
    "            # print(asset1, asset2, pc1_diff, 'noncoherent')\n",
    "            \n",
    "\n",
    "    return coherent_pair, noncoherent_pair\n"
   ],
   "execution_count":73,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"YTZ4KjUXOOGggR98zwiv3r",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Part 4: Naiive Rule-based Trading Algorithm"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"Nqxt5EA3IH5wClIWGl2rFr",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "The code below implements a rule-based pair trading strategy that is based on the 2nd principal component loadings of the asset pair to construct a market-neutral spread.\n",
    "\n",
    "Key Steps:\n",
    "1. Rolling PCA Calculation:\n",
    "\n",
    "Option 1: PCA is applied on the returns of only two selected assets. In this case, the first principal component (PC1) represents the common trend between the two selected assets.\n",
    "\n",
    "Option 2: PCA can be applied to all 11 bonds, which would make the PC1 represent the broader market trend for all treasury bonds. PC2 represents the specific factors that diverge from the broader market, allowing for more targeted trading opportunities.\n",
    "\n",
    "2. Rolling Loadings:\n",
    "\n",
    "The PCA loadings are calculated on a rolling basis to avoid look-ahead bias over time. The strategy focuses on the loadings for the second principal component (PC2), which reflects the bond-specific factors that are relatively insensitive (orthogonal) to broader market movements captured by PC1.\n",
    "The code extracts the rolling loadings of the selected assets on PC2 and uses these loadings to construct the spread.\n",
    "\n",
    "3. Spread Construction:\n",
    "\n",
    "The spread is calculated as a linear combination of the two assets' returns weighted by their PC2 loadings.\n",
    "Then the weights are normalized based on the total absolute weight of the two assets to ensure that the portfolio remains balanced.\n",
    "\n",
    "$ \\text{Spread}  = w1 * \\text{Asset 1 Return} - w2 * \\text{Asset 2 Return}$\n",
    "\n",
    "$ w1 = 1 $\n",
    "\n",
    "\n",
    "$ w2 = w1 * \\frac{\\sigma 1}{\\sigma 2} * \\frac{PC loading Asset 1}{PC Loading Asset 2} $\n",
    "\n",
    "\n",
    "\n",
    "1. Trading Signals:\n",
    "\n",
    "Buy Signal: Generated when the z-score of the spread (number of standard deviations the spread deviates from its rolling mean) falls below a specified lower threshold. This implies the spread has diverged significantly, and the strategy goes long on the spread, expecting a reversal.\n",
    "Sell Signal: Generated when the z-score rises above the upper threshold, indicating the spread has widened significantly. The strategy goes short on the spread, expecting a convergence.\n",
    "Exit Signal: The strategy closes the positions when the spread reverts to a level closer to the mean, as defined by a close threshold.\n",
    "\n",
    "5. Z-Score and Thresholds:\n",
    "\n",
    "The z-score is calculated based on the rolling mean and rolling standard deviation of the spread. This z-score is used to quantify the divergence of the spread from its historical average.\n",
    "The thresholds (upper, lower, and close) dictate when the strategy enters and exits positions.\n",
    "\n",
    "6. Performance Evaluation:\n",
    "\n",
    "The code tracks the cumulative returns of the pair trading strategy over time. It shifts the positions by one day to avoid look-ahead bias when calculating the returns for the next day.\n",
    "The final cumulative returns are plotted to visualize the strategy's performance for the selected asset pair."
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"EtKheX28n7YrMDQf952kP1",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def rolling_pca_loadings(data, window_size, num_components=2):\n",
    "    rolling_loadings = []\n",
    "    \n",
    "    for i in range(window_size, len(data) + 1):\n",
    "        window_data = data[i - window_size:i]\n",
    "        pca = PCA(n_components=num_components)\n",
    "        pca.fit(window_data)\n",
    "        loadings = pca.components_.T  \n",
    "        rolling_loadings.append(loadings)\n",
    "        \n",
    "    return np.array(rolling_loadings)\n",
    "\n",
    "def diff_sign_pc_loadings(data, window_size):\n",
    "    loadings = rolling_pca_loadings(data, window_size, num_components=2)\n",
    "    result = []\n",
    "    for matrix in loadings:\n",
    "        first_col = matrix[:, 0]\n",
    "        second_col = matrix[:, 1]\n",
    "        \n",
    "        if np.sign(first_col[0]) == np.sign(first_col[1]):\n",
    "            result.append(first_col)\n",
    "        else:\n",
    "            result.append(second_col)\n",
    "    \n",
    "    result_array = np.array(result)\n",
    "    \n",
    "    return result_array"
   ],
   "execution_count":74,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"I5JpXbpiVv7hdJGf73whLK",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Non-coherent pair\n",
    "def rule_based_strategy_info(data, window_size, upper_threshold,close_threshold, asset1,asset2):\n",
    "\n",
    "    # 1. Rolling PCA Calculation:\n",
    "    # option1: apply pca on two assets: pc1 represents the common trend between asset1 and asset 2 only\n",
    "    asset1 = f'{asset1} Return'\n",
    "    asset2 = f'{asset2} Return'\n",
    "    selected_asset_returns = data[[f'{asset1}', f'{asset2}']]\n",
    "    \n",
    "    # 2. Rolling Loadings:\n",
    "    rolling_loadings = diff_sign_pc_loadings(selected_asset_returns, window_size)\n",
    "\n",
    "    pc_loading_asset1 = rolling_loadings[:, 0] \n",
    "    pc_loading_asset2 = rolling_loadings[:, 1] \n",
    "\n",
    "    # 3. Spread Construction:\n",
    "    \n",
    "    sigma_asset1 = data[f'{asset1}'].rolling(window=window_size).std().dropna()\n",
    "    sigma_asset2 = data[f'{asset2}'].rolling(window=window_size).std().dropna()\n",
    "    pc_loading_asset1 = pd.Series(pc_loading_asset1, index = sigma_asset1.index)\n",
    "    pc_loading_asset2 = pd.Series(pc_loading_asset2, index = sigma_asset2.index)\n",
    "\n",
    "    sigma_ratio = sigma_asset1 \/ sigma_asset2\n",
    "    \n",
    "    w1 = 1\n",
    "    w2 = (w1 * sigma_ratio * pc_loading_asset1)\/pc_loading_asset2\n",
    "    \n",
    "    spread = w1 * data[f'{asset1}'] - w2 * data[f'{asset2}']\n",
    "\n",
    "    # 4. Trading Signals:\n",
    "    rolling_mean = spread.rolling(window=window_size).mean()\n",
    "    rolling_std = spread.rolling(window=window_size).std()\n",
    "\n",
    "    # 5. Z-Score and Thresholds:\n",
    "    z_score = (spread - rolling_mean) \/ rolling_std\n",
    "    \n",
    "    lower_threshold = - upper_threshold\n",
    "    \n",
    "    positions = pd.DataFrame(index=data.index, columns=['Position','Holdings_w1','Holdings_w2'])\n",
    "    \n",
    "    # Enter signal (spread deviates from the mean)\n",
    "    positions['Position'] = np.where(z_score > upper_threshold, -1, 0)\n",
    "    positions['Position'] = np.where(z_score < lower_threshold, 1, positions['Position'])\n",
    "    \n",
    "    # Exit signal (spread reverts to the mean)\n",
    "    positions['Position'] = np.where((z_score > - close_threshold) & (positions['Position'] == 1), 0, positions['Position'])\n",
    "    positions['Position'] = np.where((z_score < close_threshold) & (positions['Position'] == -1), 0, positions['Position'])\n",
    "    \n",
    "    positions['Holdings_w1'] = positions['Position'] * w1\n",
    "    positions['Holdings_w2'] = positions['Position'] * w2\n",
    "\n",
    "\n",
    "    # 6. Performance Evaluation:\n",
    "    positions_shifted = positions.shift(1)  \n",
    "    returns = positions_shifted['Holdings_w1'] * data[f'{asset1}'] + positions_shifted['Holdings_w2'] * data[f'{asset2}']\n",
    "    initial_investment = 1\n",
    "    cumulative_returns = (1+ returns).cumprod() -1\n",
    "\n",
    "    return z_score, spread, returns, cumulative_returns, positions"
   ],
   "execution_count":75,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"6whJUtfEYlt8aFZBsH4Hjn",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Non-coherent pair\n",
    "def rule_based_strategy(data, window_size, upper_threshold,close_threshold, asset1,asset2):\n",
    "\n",
    "    # 1. Rolling PCA Calculation:\n",
    "    # option1: apply pca on two assets: pc1 represents the common trend between asset1 and asset 2 only\n",
    "    asset1 = f'{asset1} Return'\n",
    "    asset2 = f'{asset2} Return'\n",
    "    selected_asset_returns = data[[f'{asset1}', f'{asset2}']]\n",
    "    \n",
    "    # 2. Rolling Loadings:\n",
    "    rolling_loadings = diff_sign_pc_loadings(selected_asset_returns, window_size)\n",
    "\n",
    "    pc_loading_asset1 = rolling_loadings[:, 0] \n",
    "    pc_loading_asset2 = rolling_loadings[:, 1] \n",
    "\n",
    "    # 3. Spread Construction:\n",
    "    \n",
    "    sigma_asset1 = data[f'{asset1}'].rolling(window=window_size).std().dropna()\n",
    "    sigma_asset2 = data[f'{asset2}'].rolling(window=window_size).std().dropna()\n",
    "    pc_loading_asset1 = pd.Series(pc_loading_asset1, index = sigma_asset1.index)\n",
    "    pc_loading_asset2 = pd.Series(pc_loading_asset2, index = sigma_asset2.index)\n",
    "\n",
    "    sigma_ratio = sigma_asset1 \/ sigma_asset2\n",
    "    \n",
    "    w1 = 1\n",
    "    w2 = (w1 * sigma_ratio * pc_loading_asset1)\/pc_loading_asset2\n",
    "    \n",
    "    spread = w1 * data[f'{asset1}'] - w2 * data[f'{asset2}']\n",
    "\n",
    "    # 4. Trading Signals:\n",
    "    rolling_mean = spread.rolling(window=window_size).mean()\n",
    "    rolling_std = spread.rolling(window=window_size).std()\n",
    "\n",
    "    # 5. Z-Score and Thresholds:\n",
    "    z_score = (spread - rolling_mean) \/ rolling_std\n",
    "    \n",
    "    lower_threshold = - upper_threshold\n",
    "    \n",
    "    positions = pd.DataFrame(index=data.index, columns=['Position','Holdings_w1','Holdings_w2'])\n",
    "    \n",
    "    # Enter signal (spread deviates from the mean)\n",
    "    positions['Position'] = np.where(z_score > upper_threshold, -1, 0)\n",
    "    positions['Position'] = np.where(z_score < lower_threshold, 1, positions['Position'])\n",
    "    \n",
    "    # Exit signal (spread reverts to the mean)\n",
    "    positions['Position'] = np.where((z_score > - close_threshold) & (positions['Position'] == 1), 0, positions['Position'])\n",
    "    positions['Position'] = np.where((z_score < close_threshold) & (positions['Position'] == -1), 0, positions['Position'])\n",
    "    \n",
    "    positions['Holdings_w1'] = positions['Position'] * w1\n",
    "    positions['Holdings_w2'] = positions['Position'] * w2\n",
    "\n",
    "\n",
    "    # 6. Performance Evaluation:\n",
    "    positions_shifted = positions.shift(1)  \n",
    "    returns = positions_shifted['Holdings_w1'] * data[f'{asset1}'] + positions_shifted['Holdings_w2'] * data[f'{asset2}']\n",
    "    initial_investment = 1\n",
    "    cumulative_returns = (1+ returns).cumprod() -1\n",
    "\n",
    "    return cumulative_returns[-1]"
   ],
   "execution_count":76,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"yIwOIiFivIeBnrCHKphv3n",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### Grid search for the optimal parameters"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"ixNDbv1uRxqyLsDNxbEAFw",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def optimize_parameters(data, noncoherent_pair, window_size_list, upper_threshold_list, close_threshold_list):\n",
    "\n",
    "    param_results = {}\n",
    "    pair_results = {}\n",
    "    \n",
    "    # Try each parameter combination\n",
    "    for window_size, upper_threshold, close_threshold in itertools.product(\n",
    "            window_size_list, upper_threshold_list, close_threshold_list):\n",
    "        \n",
    "        if close_threshold >= upper_threshold:\n",
    "            continue\n",
    "            \n",
    "        returns = []\n",
    "        pair_details = []\n",
    "        \n",
    "        for asset_pair in noncoherent_pair:\n",
    "            asset1 = asset_pair[0]#.replace(' Adjusted Return', '')\n",
    "            asset2 = asset_pair[1]#.replace(' Adjusted Return', '')\n",
    "            \n",
    "            # Get return for this pair with current parameters\n",
    "            result = rule_based_strategy(data, window_size, upper_threshold, close_threshold, asset1, asset2)\n",
    "            returns.append(result)\n",
    "            \n",
    "            pair_details.append({'asset1': asset1, 'asset2': asset2, 'return': result})\n",
    "        \n",
    "        # Store average return for this parameter combination\n",
    "        param_key = (window_size, upper_threshold, close_threshold)\n",
    "        param_results[param_key] = {'avg_return': np.mean(returns),'pair_details': pair_details}\n",
    "\n",
    "    \n",
    "    # Find best parameter combination\n",
    "    best_params = max(param_results.items(), key=lambda x: x[1]['avg_return'])\n",
    "    window_size, upper_threshold, close_threshold = best_params[0]\n",
    "    \n",
    "    \n",
    "    return upper_threshold, close_threshold, window_size\n"
   ],
   "execution_count":77,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"XRsls6Nfsnf8IH9smFPzm1",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Part 5: Reinforcement Learning Based Strategy"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"8u7rXTvSP7fwoHt4ULmkGb",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "To enhance the existing rule-based strategy for pair trading using a Deep Q-Network (DQN), we can replace the rule-based signals with a reinforcement learning (RL) approach. The purpose for RL step is to find 'when' to trade and 'how much' to trade by interacting with observation space, action space and reward space.\n",
    "\n",
    "Key Points:\n",
    "\n",
    "Teachnique: DQN Strategy\n",
    "\n",
    "Dynamic Pair Selection & Training Process\n",
    "1. Formation Period (Year T): Select correlated pairs using PCA\n",
    "2. Training Period (Year T+1): Train RL agent on selected pairs\n",
    "3. Testing Period (Year T+2): Test agent on newly generated pairs\n",
    "4. Repeat process by rolling forward one year for robust validation\n",
    "\n",
    "![image.png](attachment:.\/attachment:853841c4-393a-4b7c-870b-290257aa81f2.png)\n",
    "\n",
    "Model Architecture\n",
    "1. Deep Q-Network (DQN) for automated trading decisions \n",
    "2. State space includes normalized spread, z-score, position metrics\n",
    "3. Action space: Long (1), Neutral (0), Short (-1) positions\n",
    "4. Reward = Return - beta * (RL action - rule-based strategy action)\n",
    "\n",
    "Training Process:\n",
    "1. the agent learns optimal entry and exit points through extensive episodes with different pairs and market conditions\n",
    "2. Set the network with highest reward as target network, agent continuously learns to match or exceed this taret network performance\n",
    "3. the agent develop resilience to both regime changes and switching between different asset pairs, making it truly adaptive to market dynamics."
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"1t1thSUrnrGfT0e7KT2s4B",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# defines a new class called DQN that inherits from PyTorch's nn.Module. \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# todo: to be fine-tuned\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_sizes,activation = 'relu', dropout_rate=0.2):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if activation == 'relu':\n",
    "            act_fn = nn.ReLU()\n",
    "        elif activation == 'leaky_relu':\n",
    "            act_fn = nn.LeakyReLU(0.01)\n",
    "        elif activation == 'elu':\n",
    "            act_fn = nn.ELU()\n",
    "        elif activation == 'selu':\n",
    "            act_fn = nn.SELU()\n",
    "        elif activation == 'tanh':\n",
    "            act_fn = nn.Tanh()\n",
    "\n",
    "    \n",
    "        # Input layer\n",
    "        # Input layer with proper initialization\n",
    "        input_layer = nn.Linear(state_size, hidden_sizes[0])\n",
    "        nn.init.xavier_uniform_(input_layer.weight)\n",
    "        nn.init.zeros_(input_layer.bias)\n",
    "        self.layers.append(input_layer)\n",
    "        self.layers.append(act_fn)\n",
    "        \n",
    "        # Hidden layers with proper initialization\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            hidden_layer = nn.Linear(hidden_sizes[i-1], hidden_sizes[i])\n",
    "            nn.init.xavier_uniform_(hidden_layer.weight)\n",
    "            nn.init.zeros_(hidden_layer.bias)\n",
    "            self.layers.append(hidden_layer)\n",
    "            self.layers.append(act_fn)\n",
    "            \n",
    "            if dropout_rate > 0:\n",
    "                self.layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        # Output layer with proper initialization\n",
    "        output_layer = nn.Linear(hidden_sizes[-1], action_size)\n",
    "        nn.init.xavier_uniform_(output_layer.weight)\n",
    "        nn.init.zeros_(output_layer.bias)\n",
    "        self.layers.append(output_layer)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = state\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "# creates a named tuple to store experience replays. a convenient way to group related data.\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state', 'done'))"
   ],
   "execution_count":105,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"LUtuzOYD0iR1wibeNKYcJd",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ],
   "execution_count":79,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"smThOdR5upzpg1qwIoAcE3",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size,hidden_size, learning_rate=1e-5):\n",
    "        self.hidden_size= hidden_size\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = ReplayBuffer(10000) # a replay buffer with a capacity of 10,000 experiences\n",
    "        self.gamma = 0.95    # discount factor\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = learning_rate\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.policy_net = DQN(state_size, action_size,hidden_size).to(self.device)\n",
    "        self.target_net = DQN(state_size, action_size,hidden_size).to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate) #update for policy network's weight\n",
    "        self.training_rmse_history = []  # Track training RMSE\n",
    "        self.q_value_history = []  # Store Q-value predictions\n",
    "        self.actual_returns_history = []  # Store actual returns\n",
    "        self.next_states = []\n",
    "\n",
    "        \n",
    "    def act(self, state, store_next_state = None):\n",
    "        if random.random() <= self.epsilon: # exploration (random act)\n",
    "            self.q_value_history.append(0)\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "\n",
    "            state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "            action_values = self.policy_net(state)\n",
    "            action = action_values.max(1)[1].item()\n",
    "\n",
    "            q_value = action_values[0][action].item()\n",
    "\n",
    "            if not np.isnan(q_value):\n",
    "                self.q_value_history.append(q_value)\n",
    "            else:\n",
    "                self.q_value_history.append(0)\n",
    "\n",
    "            return action\n",
    "\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.push(state, action, reward, next_state, done) # add new experience to replay buffer\n",
    "\n",
    "    def learn(self):\n",
    "\n",
    "        if len(self.memory) < self.batch_size: # check if enough space in buffer\n",
    "            return\n",
    "        \n",
    "        transitions = self.memory.sample(self.batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        \n",
    "        state_batch = torch.FloatTensor(batch.state).to(self.device)\n",
    "        action_batch = torch.LongTensor(batch.action).unsqueeze(1).to(self.device)\n",
    "        reward_batch = torch.FloatTensor(batch.reward).to(self.device)\n",
    "        next_state_batch = torch.FloatTensor(np.array(batch.next_state)).to(self.device)\n",
    "\n",
    "\n",
    "        # pass our batch of states through our policy network to get Q-values for all actions. \n",
    "        # use gather to select only the Q-values for the actions that were actually taken. This gives us our current estimate of the Q-values for our sampled state-action pairs\n",
    "        current_q_values = self.policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # For each non-terminal next state, we compute the maximum Q-value using our target network. \n",
    "        # We use the target network (which is updated less frequently) to provide a more stable target for learning.\n",
    "        next_states = torch.FloatTensor([s for s in batch.next_state if s is not None]).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if next_states.size(0) > 0:\n",
    "                next_actions = self.policy_net(next_states).max(1)[1]\n",
    "                next_state_values = self.target_net(next_states).gather(1, next_actions.unsqueeze(1))\n",
    "            else:\n",
    "                next_state_values = torch.zeros_like(current_q_values)\n",
    "\n",
    "        expected_q_values = (next_state_values * self.gamma) + reward_batch.unsqueeze(1)\n",
    "\n",
    "\n",
    "        # Weighted loss\n",
    "        mse_loss = F.mse_loss(current_q_values, expected_q_values)\n",
    "        # loss =  F.smooth_l1_loss(current_q_values, expected_q_values)\n",
    "        training_rmse  = torch.sqrt(mse_loss)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        mse_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.training_rmse_history.append(training_rmse.item()) \n",
    "\n",
    "        return training_rmse.item()\n",
    "\n",
    "\n",
    "\n",
    "    # as we have more training samples, we don't need to explore too often\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "    def calculate_testing_rmse(self):\n",
    "        if not self.next_states:\n",
    "            return None\n",
    "            \n",
    "        with torch.no_grad():\n",
    " \n",
    "            next_state = torch.FloatTensor(self.next_states).to(self.device)\n",
    "            next_actions = self.policy_net(next_state).max(1)[1]\n",
    "            next_state_values = self.target_net(next_state).gather(1, next_actions.unsqueeze(1))\n",
    "\n",
    "            rewards = torch.FloatTensor(self.actual_returns_history).to(self.device)\n",
    "\n",
    "            target_q_values = rewards + (self.gamma * next_state_values.squeeze())\n",
    "            \n",
    "            predicted_q_values = torch.FloatTensor(self.q_value_history).to(self.device)\n",
    "        \n",
    "            bellman_error = torch.sqrt(F.mse_loss(predicted_q_values, target_q_values))\n",
    "            \n",
    "            return bellman_error.item()\n",
    "\n",
    "    \n",
    "    def reset_test_history(self):\n",
    "\n",
    "        self.q_value_history = []\n",
    "        self.actual_returns_history = []\n",
    "        self.next_states = []"
   ],
   "execution_count":106,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"gaC4FLYS2FDxpOeI65S98D",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "class MultiPairTradingEnv:\n",
    "    def __init__(self, asset_returns_raw, pair_list, upper_threshold, close_threshold, window_size, beta):\n",
    "        self.asset_returns_raw = asset_returns_raw\n",
    "        self.pair_list = pair_list  \n",
    "        self.window_size = window_size\n",
    "        self.upper_threshold = upper_threshold\n",
    "        self.close_threshold = close_threshold\n",
    "        self.beta = beta\n",
    "        self.action_space = [-1, 0, 1]\n",
    "        \n",
    "        # Initialize spreads for all pairs\n",
    "        self.spreads = {}\n",
    "        self.w2s = {}\n",
    "        for asset1, asset2 in pair_list:\n",
    "            spread, w2 = self._calculate_spread(asset1, asset2)\n",
    "            self.spreads[(asset1, asset2)] = spread\n",
    "            self.w2s[(asset1, asset2)] = w2\n",
    "        \n",
    "        # Initialize training variables\n",
    "        self.reset()\n",
    "\n",
    "    def _calculate_spread(self, asset1, asset2):\n",
    "        \"\"\"Calculate spread for a given pair\"\"\"\n",
    "        selected_asset_returns = self.asset_returns_raw[[f'{asset1} Return', f'{asset2} Return']]\n",
    "        \n",
    "        rolling_loadings = diff_sign_pc_loadings(selected_asset_returns, self.window_size)\n",
    "        pc_loading_asset1 = rolling_loadings[:, 0]\n",
    "        pc_loading_asset2 = rolling_loadings[:, 1]\n",
    "        \n",
    "        sigma_asset1 = self.asset_returns_raw[f'{asset1} Return'].rolling(window=self.window_size).std().dropna()\n",
    "        sigma_asset2 = self.asset_returns_raw[f'{asset2} Return'].rolling(window=self.window_size).std().dropna()\n",
    "        \n",
    "        pc_loading_asset1 = pd.Series(pc_loading_asset1, index=sigma_asset1.index)\n",
    "        pc_loading_asset2 = pd.Series(pc_loading_asset2, index=sigma_asset2.index)\n",
    "        sigma_ratio = sigma_asset1 \/ sigma_asset2\n",
    "        \n",
    "        w1 = 1\n",
    "        w2 = (w1 * sigma_ratio * pc_loading_asset2) \/ pc_loading_asset1\n",
    "        total_weight = abs(w1) + abs(w2)\n",
    "        w1 = w1 \/ total_weight\n",
    "        w2 = w2 \/ total_weight\n",
    "\n",
    "        spread = w1 * self.asset_returns_raw[f'{asset1} Return'] - w2 * self.asset_returns_raw[f'{asset2} Return']\n",
    "        \n",
    "        return spread, w2\n",
    "\n",
    "    def reset(self,ifbacktest = False, pair = []):\n",
    "        # Randomly select a pair\n",
    "        if ifbacktest:\n",
    "            self.current_pair = pair\n",
    "        else:\n",
    "            self.current_pair = random.choice(self.pair_list)\n",
    "        self.asset1, self.asset2 = self.current_pair\n",
    "        # Get spread and w2 for selected pair\n",
    "        self.spread = self.spreads[self.current_pair]\n",
    "        self.w2 = self.w2s[self.current_pair]\n",
    "        \n",
    "        # Reset position and portfolio\n",
    "        self.position = 0\n",
    "        self.previous_position = 0\n",
    "        self.portfolio_value = 1\n",
    "        self.steps_taken = 0\n",
    "        self.cumulative_return = [self.portfolio_value]\n",
    "        # Reset tracking variables\n",
    "        self.portfolio_start_value = self.portfolio_value\n",
    "        self.last_position_change = None\n",
    "        self.position_start_value = None\n",
    "        self.return_list = []\n",
    "        self.action_history = []\n",
    "        self.reward = 0\n",
    "        \n",
    "        self.current_step = self.window_size\n",
    "        \n",
    "        return self._get_normalized_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.steps_taken += 1\n",
    "        self.previous_position = self.position\n",
    "        new_position = self.action_space[action]\n",
    "        \n",
    "        # Handle position changes\n",
    "        portfolio_reward = 0\n",
    "        if new_position != 0 and self.previous_position == 0:\n",
    "            self.last_position_change = self.current_step\n",
    "            self.position_start_value = self.portfolio_value\n",
    "        elif new_position == 0 and self.previous_position != 0:\n",
    "            self.last_position_change = None\n",
    "            self.position_start_value = None\n",
    "            portfolio_reward = self._calculate_portfolio_reward()\n",
    "\n",
    "        self.position = new_position\n",
    "        \n",
    "        # Calculate rewards\n",
    "        spread_return = self._calculate_immediate_reward()\n",
    "        baseline_action = self._get_baseline_action()\n",
    "        deviation_penalty = self.beta * abs(new_position - baseline_action)\n",
    "        self.reward = portfolio_reward - deviation_penalty\n",
    "\n",
    "        # Update portfolio value\n",
    "        self.return_list.append(1 + spread_return)\n",
    "        self.cumulative_return = np.cumprod(self.return_list) -1\n",
    "        self.portfolio_value = self.cumulative_return[-1]\n",
    "        \n",
    "        # Store action\n",
    "        self.action_history.append({\n",
    "            'step': self.current_step,\n",
    "            'pair': self.current_pair,\n",
    "            'position': self.position,\n",
    "            'reward': self.reward,\n",
    "            'spread_return': spread_return,\n",
    "            'portfolio_value': self.portfolio_value,\n",
    "            'cumulative_return': self.cumulative_return\n",
    "        })\n",
    "        \n",
    "        # Advance step\n",
    "        self.current_step += 1\n",
    "        \n",
    "        # Episode ends after 1000 steps or at end of data\n",
    "        done = self.current_step >= len(self.spread) - 1\n",
    "        \n",
    "        # Close position at end of episode\n",
    "        if done and self.position != 0:\n",
    "            self.position = 0\n",
    "            portfolio_reward = self._calculate_portfolio_reward()\n",
    "            self.reward += portfolio_reward\n",
    "        \n",
    "        return self._get_normalized_state(), self.reward, done, {\n",
    "            'pair': self.current_pair,\n",
    "            'portfolio_value': self.portfolio_value,\n",
    "            'spread_return': spread_return,\n",
    "            'deviation_penalty': deviation_penalty\n",
    "        }\n",
    "\n",
    "    def _get_normalized_state(self):\n",
    "        \"\"\"Get normalized state representation\"\"\"\n",
    "        spread = self.spread.iloc[self.current_step]\n",
    "        z_score = self._calculate_z_score(spread)\n",
    "        \n",
    "        return np.array([\n",
    "            self.position, \n",
    "            spread,\n",
    "            z_score\n",
    "        ])\n",
    "\n",
    "\n",
    "    def _calculate_z_score(self, spread):\n",
    "        if self.current_step < self.window_size:\n",
    "            return 0  \n",
    "        window = self.spread.iloc[self.current_step - self.window_size:self.current_step]\n",
    "        std_dev = window.std()\n",
    "        if std_dev == 0 or np.isnan(std_dev):\n",
    "            return 0  \n",
    "        return (spread - window.mean()) \/ std_dev\n",
    "\n",
    "    def _calculate_portfolio_reward(self):\n",
    "        if self.position_start_value is None:\n",
    "            return 0\n",
    "        return (self.portfolio_value - self.position_start_value) \/ self.position_start_value\n",
    "\n",
    "    def _calculate_immediate_reward(self):\n",
    "        asset1_return = self.asset_returns_raw[f'{self.asset1} Return'].iloc[self.current_step]\n",
    "        asset2_return = self.asset_returns_raw[f'{self.asset2} Return'].iloc[self.current_step]\n",
    "        prev_index = self.asset_returns_raw.index[self.current_step-1]\n",
    "        w2_prev = self.w2.loc[prev_index]\n",
    "        \n",
    "        spread_return = asset1_return - w2_prev * asset2_return\n",
    "\n",
    "        \n",
    "        return self.previous_position * spread_return\n",
    "    \n",
    "    def _get_baseline_action(self):\n",
    "        z_score = self._calculate_z_score(self.spread.iloc[self.current_step])\n",
    "        lower_threshold = -1 * self.upper_threshold\n",
    "        \n",
    "        if z_score > self.upper_threshold and self.position < 0:  # short signal\n",
    "            return -1\n",
    "        elif z_score < lower_threshold and self.position > 0:  # long signal\n",
    "            return 1\n",
    "        elif abs(z_score) < self.close_threshold and self.position == 0:  # neutral\n",
    "            return 0\n",
    "        \n",
    "        return self.position  \n",
    "    "
   ],
   "execution_count":119,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"wRhppbYI0DdPVGNLwwiDYz",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def train_multi_pair_dqn(env, episodes, hidden_size, batch_size=32):\n",
    "    state_size = 3  # position, spread, z-score\n",
    "    action_size = len(env.action_space)\n",
    "    \n",
    "    agent = DQNAgent(state_size, action_size, hidden_size)\n",
    "    \n",
    "    # Initialize training metrics for each pair\n",
    "    training_metrics = {\n",
    "\n",
    "        'pair_performance': {pair: {\n",
    "            'rewards': [],\n",
    "            'portfolio_values': [],\n",
    "            'best_portfolio_value': float('-inf'),\n",
    "            'best_model_rmse': float('-inf'),\n",
    "            'best_reward': float('-inf'),\n",
    "            'best_cumulative_return':[],\n",
    "            'best_state_dict': None\n",
    "        } for pair in env.pair_list}\n",
    "    }\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        current_pair = env.current_pair\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        episode_training_rmse = []\n",
    "        agent.reset_test_history()\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            agent.memory.push(state, action, reward, next_state, done)\n",
    "            if len(agent.memory) > batch_size:\n",
    "                training_rmse = agent.learn()\n",
    "                if training_rmse is not None:\n",
    "                    episode_training_rmse.append(training_rmse)\n",
    "\n",
    "            # Store Q-value prediction and actual return for testing RMSE\n",
    "            agent.actual_returns_history.append(reward)\n",
    "            \n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "        return_qvalue_rmse = agent.calculate_testing_rmse()\n",
    "        \n",
    "        # Store pair-specific metrics\n",
    "        pair_metrics = training_metrics['pair_performance'][current_pair]\n",
    "        pair_metrics['rewards'].append(episode_reward)\n",
    "        pair_metrics['portfolio_values'].append(env.portfolio_value)\n",
    "        \n",
    "        # Update best model for current pair if performance improves\n",
    "        if episode_reward > pair_metrics['best_reward']:\n",
    "            pair_metrics['best_portfolio_value'] = env.portfolio_value\n",
    "            pair_metrics['best_reward'] = episode_reward\n",
    "            pair_metrics['best_state_dict'] = agent.policy_net.state_dict()\n",
    "            pair_metrics['best_cumulative_return'] = env.cumulative_return\n",
    "            current_rmse = np.mean(episode_training_rmse) if episode_training_rmse else float('inf')\n",
    "            pair_metrics['best_model_rmse'] = current_rmse\n",
    "            # pair_metrics['best_model_rmse'] = return_qvalue_rmse\n",
    "\n",
    "            # Update target network with best model\n",
    "            agent.target_net.load_state_dict(pair_metrics['best_state_dict'])\n",
    "\n",
    "        agent.decay_epsilon()\n",
    "\n",
    "    # Find the best performing model across all pairs\n",
    "    best_pair = max(training_metrics['pair_performance'].items(),\n",
    "                   key=lambda x: x[1]['best_reward'])[0]\n",
    "    best_metrics = training_metrics['pair_performance'][best_pair]\n",
    "    \n",
    "    agent.target_net.load_state_dict(best_metrics['best_state_dict'])\n",
    "    \n",
    "    return agent, training_metrics\n",
    "\n",
    "def backtest(env, agent, target_pair):\n",
    "    state = env.reset(True, target_pair)\n",
    "    done = False\n",
    "    agent.reset_test_history()\n",
    "\n",
    "    while not done:\n",
    "        \n",
    "        action = agent.act(state)\n",
    "\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        agent.actual_returns_history.append(reward)\n",
    "  \n",
    "        if next_state is not None: # new added\n",
    "            agent.next_states.append(next_state)\n",
    "        else:\n",
    "            agent.next_states.append(0)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    # Calculate testing RMSE for the backtest\n",
    "    testing_rmse = agent.calculate_testing_rmse()\n",
    "\n",
    "    backtest_results = {\n",
    "        'action_history': env.action_history,\n",
    "        'testing_rmse': testing_rmse\n",
    "    }\n",
    "\n",
    "    return backtest_results"
   ],
   "execution_count":107,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"cjEYx1zmudnros7uHxGAHx",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "def plot_cumulative_returns(dates, training_returns, pair, type):\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(dates, training_returns, label='Returns')\n",
    "    plt.title(f'Cumulative Returns for {pair[0]} and {pair[1]} in {type} set')\n",
    "    plt.xlabel('Dates')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_last_cumulative_return(dates, action_results, target_pair):\n",
    "    action_history = action_results['action_history']\n",
    "\n",
    "    pair_actions = [action for action in action_history if action['pair'] == target_pair]\n",
    "    \n",
    "    if pair_actions:\n",
    "        last_action = pair_actions[-1]\n",
    "        cumulative_return = last_action['cumulative_return']\n",
    "        # plot_cumulative_returns(dates, cumulative_return, target_pair, 'Testing')\n",
    "        rmse = action_results['testing_rmse']\n",
    "        mean_return, sharpe = get_summary(cumulative_return)\n",
    "\n",
    "        return {\n",
    "        'Mean Return (%) Annual': \"{:.4f}\".format(mean_return),\n",
    "        'Sharpe Ratio Annual': \"{:.4f}\".format(sharpe),\n",
    "        'RMSE':\"{:.4f}\".format(rmse)\n",
    "    }\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_summary(cumulative_return):\n",
    "\n",
    "    periodic_returns = (1 + cumulative_return[1:]) \/ (1+cumulative_return[:-1]) - 1\n",
    "    periodic_returns = periodic_returns[~np.isinf(periodic_returns) & ~np.isneginf(periodic_returns)]\n",
    "    periodic_returns = periodic_returns[~np.isnan(periodic_returns)]\n",
    "    # Mean return\n",
    "    mean_return = np.mean(periodic_returns) *252 * 100\n",
    "    \n",
    "    # Sharpe ratio (assuming risk-free rate = 0)\n",
    "    sharpe = (np.mean(periodic_returns) \/ np.std(periodic_returns))* np.sqrt(252)\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative = np.array(cumulative_return)\n",
    "    running_max = np.maximum.accumulate(cumulative)\n",
    "\n",
    "\n",
    "    return mean_return, sharpe\n"
   ],
   "execution_count":83,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"UnQLGJPYHFjp1iGgkzUbhP",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# train model pair by pair\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    start_year = 2014\n",
    "    end_year = 2024\n",
    "    summary_data = []\n",
    "  \n",
    "    training_testing_Split = '2018-12-31'\n",
    "    train_period = tr_dm_net[tr_dm_net.index <= training_testing_Split]\n",
    "    formation_period = train_period\n",
    "    test_period = tr_dm_net[tr_dm_net.index > training_testing_Split]\n",
    "\n",
    "    formation_period_price = tr_dm_net_price[tr_dm_net_price.index <= training_testing_Split]\n",
    "    train_period_price = tr_dm_net_price[tr_dm_net_price.index > training_testing_Split]\n",
    "\n",
    "\n",
    "    coherent_pairs_in_formation, noncoherent_pair = noncoherent_pair_cluster(formation_period, formation_period_price)\n",
    "\n",
    "    window_size_list = [30, 60]\n",
    "    upper_threshold_list = [1.0, 1.25, 1.5,1.75]\n",
    "    close_threshold_list = [0.1 , 0.2]\n",
    "\n",
    "    upper_threshold, close_threshold, window_size = optimize_parameters(train_period, coherent_pairs_in_formation, window_size_list, upper_threshold_list,close_threshold_list)\n",
    "    # upper_threshold = 1.0\n",
    "    # close_threshold = 0.1\n",
    "    # window_size = 60\n",
    "    # beta = 0.1\n",
    "\n",
    "\n",
    "    hidden_size_list = [[128,128],[128,64],[2],[5,5],[5,2],[5],[2,2,2]]\n",
    "\n",
    "    for pair in coherent_pairs_in_formation:\n",
    "        env = MultiPairTradingEnv(train_period, [pair], upper_threshold, close_threshold, window_size, beta)\n",
    "\n",
    "        for hidden_size in hidden_size_list:\n",
    "            \n",
    "            train_agent, train_env = train_multi_pair_dqn(env, episodes=100, hidden_size = hidden_size)\n",
    "\n",
    "            training_dates = train_period.index[window_size+1:]\n",
    "\n",
    "            best_cumulative_return = train_env['pair_performance'][pair]['best_cumulative_return']\n",
    "            rmse = train_env['pair_performance'][pair]['best_model_rmse']\n",
    "            # plot_cumulative_returns(training_dates, best_cumulative_return, pair, 'Training')\n",
    "            mean_return, sharpe = get_summary(best_cumulative_return)\n",
    "\n",
    "            summary_training = {'Mean Return (%) Annual': \"{:.4f}\".format(mean_return),\n",
    "                                'Sharpe Ratio Annual': \"{:.4f}\".format(sharpe),'RMSE':\"{:.4f}\".format(rmse)}\n",
    "            \n",
    "            summary_training['Pair'] = f\"{pair[0]}-{pair[1]}\"\n",
    "            summary_training['Data Type'] = 'Train Data'\n",
    "            summary_training['Hidden Size'] = '-'.join(str(layer) for layer in hidden_size)\n",
    "\n",
    "            summary_data.append(summary_training)\n",
    "\n",
    "            # Backtest\n",
    "\n",
    "            env_test = MultiPairTradingEnv(test_period, [pair], upper_threshold, close_threshold, window_size, beta)\n",
    "            testing_dates = test_period.index[window_size+1:]\n",
    "\n",
    "            backtest_results = backtest(env_test, train_agent, pair)\n",
    "            summary_testing = get_last_cumulative_return(testing_dates, backtest_results, pair)\n",
    "            summary_testing['Pair'] = f\"{pair[0]}-{pair[1]}\"\n",
    "            summary_testing['Data Type'] = 'Test Data'\n",
    "            summary_testing['Hidden Size'] = '-'.join(str(layer) for layer in hidden_size)\n",
    "\n",
    "            summary_data.append(summary_testing)\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    columns = ['Data Type', 'Hidden Size', 'Pair', 'Mean Return (%) Annual', 'Sharpe Ratio Annual','RMSE']\n",
    "    summary_df = summary_df[columns]\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ],
   "execution_count":116,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"pCy9aCoFGXf7oFzi2Gi9rK",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "pivot_df = pd.pivot_table(\n",
    "   summary_df,\n",
    "   index=['Hidden Size', 'Pair'],\n",
    "   columns='Data Type',\n",
    "   values=['Mean Return (%) Annual', 'Sharpe Ratio Annual','RMSE'],\n",
    "   aggfunc='first' \n",
    ").round(4)\n",
    "pivot_df.head(60)"
   ],
   "execution_count":117,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th colspan=\"2\" halign=\"left\">Mean Return (%) Annual<\/th>\n",
       "      <th colspan=\"2\" halign=\"left\">RMSE<\/th>\n",
       "      <th colspan=\"2\" halign=\"left\">Sharpe Ratio Annual<\/th>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th><\/th>\n",
       "      <th>Data Type<\/th>\n",
       "      <th>Test Data<\/th>\n",
       "      <th>Train Data<\/th>\n",
       "      <th>Test Data<\/th>\n",
       "      <th>Train Data<\/th>\n",
       "      <th>Test Data<\/th>\n",
       "      <th>Train Data<\/th>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>Hidden Size<\/th>\n",
       "      <th>Pair<\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">128-128<\/th>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>0.7632<\/td>\n",
       "      <td>-1.3551<\/td>\n",
       "      <td>0.0460<\/td>\n",
       "      <td>0.0454<\/td>\n",
       "      <td>0.1458<\/td>\n",
       "      <td>-0.3433<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTSEK10Y Govt Adjusted<\/th>\n",
       "      <td>-3.1340<\/td>\n",
       "      <td>1.2429<\/td>\n",
       "      <td>0.0112<\/td>\n",
       "      <td>0.0172<\/td>\n",
       "      <td>-0.7640<\/td>\n",
       "      <td>0.4125<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCHF10Y Govt Adjusted<\/th>\n",
       "      <td>2.8136<\/td>\n",
       "      <td>-1.1739<\/td>\n",
       "      <td>0.1093<\/td>\n",
       "      <td>0.0810<\/td>\n",
       "      <td>0.7294<\/td>\n",
       "      <td>-0.3457<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>-1.0854<\/td>\n",
       "      <td>-0.0349<\/td>\n",
       "      <td>0.0079<\/td>\n",
       "      <td>0.0395<\/td>\n",
       "      <td>-0.2958<\/td>\n",
       "      <td>-0.0123<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">128-64<\/th>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>0.6224<\/td>\n",
       "      <td>-1.5462<\/td>\n",
       "      <td>0.0154<\/td>\n",
       "      <td>0.0376<\/td>\n",
       "      <td>0.1291<\/td>\n",
       "      <td>-0.3728<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTSEK10Y Govt Adjusted<\/th>\n",
       "      <td>-0.7632<\/td>\n",
       "      <td>-1.1051<\/td>\n",
       "      <td>0.0885<\/td>\n",
       "      <td>0.0386<\/td>\n",
       "      <td>-0.1878<\/td>\n",
       "      <td>-0.3665<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCHF10Y Govt Adjusted<\/th>\n",
       "      <td>-3.7500<\/td>\n",
       "      <td>-2.1861<\/td>\n",
       "      <td>0.0156<\/td>\n",
       "      <td>0.1244<\/td>\n",
       "      <td>-0.9418<\/td>\n",
       "      <td>-0.6386<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>-1.0889<\/td>\n",
       "      <td>-0.3130<\/td>\n",
       "      <td>0.0044<\/td>\n",
       "      <td>0.0343<\/td>\n",
       "      <td>-0.2993<\/td>\n",
       "      <td>-0.1100<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2<\/th>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>2.1849<\/td>\n",
       "      <td>-1.4602<\/td>\n",
       "      <td>0.1394<\/td>\n",
       "      <td>0.3331<\/td>\n",
       "      <td>0.4271<\/td>\n",
       "      <td>-0.3499<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTSEK10Y Govt Adjusted<\/th>\n",
       "      <td>0.6049<\/td>\n",
       "      <td>-0.2010<\/td>\n",
       "      <td>0.7759<\/td>\n",
       "      <td>0.6066<\/td>\n",
       "      <td>0.1474<\/td>\n",
       "      <td>-0.0664<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCHF10Y Govt Adjusted<\/th>\n",
       "      <td>-0.8909<\/td>\n",
       "      <td>0.3154<\/td>\n",
       "      <td>0.1547<\/td>\n",
       "      <td>0.4272<\/td>\n",
       "      <td>-0.2399<\/td>\n",
       "      <td>0.0906<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>2.3931<\/td>\n",
       "      <td>0.0251<\/td>\n",
       "      <td>0.4754<\/td>\n",
       "      <td>0.7714<\/td>\n",
       "      <td>0.6473<\/td>\n",
       "      <td>0.0091<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2-2-2<\/th>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>-2.7952<\/td>\n",
       "      <td>-0.5051<\/td>\n",
       "      <td>0.0020<\/td>\n",
       "      <td>0.0010<\/td>\n",
       "      <td>-0.5609<\/td>\n",
       "      <td>-0.1201<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTSEK10Y Govt Adjusted<\/th>\n",
       "      <td>-2.7889<\/td>\n",
       "      <td>-0.0055<\/td>\n",
       "      <td>0.0009<\/td>\n",
       "      <td>0.0016<\/td>\n",
       "      <td>-0.6777<\/td>\n",
       "      <td>-0.0018<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCHF10Y Govt Adjusted<\/th>\n",
       "      <td>-1.3337<\/td>\n",
       "      <td>0.8738<\/td>\n",
       "      <td>0.1366<\/td>\n",
       "      <td>0.1220<\/td>\n",
       "      <td>-0.3453<\/td>\n",
       "      <td>0.2475<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>-0.2176<\/td>\n",
       "      <td>-0.3933<\/td>\n",
       "      <td>0.0012<\/td>\n",
       "      <td>0.0066<\/td>\n",
       "      <td>-0.0592<\/td>\n",
       "      <td>-0.1295<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5<\/th>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>0.8838<\/td>\n",
       "      <td>-1.7047<\/td>\n",
       "      <td>0.6780<\/td>\n",
       "      <td>1.0870<\/td>\n",
       "      <td>0.1727<\/td>\n",
       "      <td>-0.4014<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTSEK10Y Govt Adjusted<\/th>\n",
       "      <td>-3.4037<\/td>\n",
       "      <td>-0.9779<\/td>\n",
       "      <td>0.1323<\/td>\n",
       "      <td>0.2080<\/td>\n",
       "      <td>-0.8435<\/td>\n",
       "      <td>-0.3201<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCHF10Y Govt Adjusted<\/th>\n",
       "      <td>-1.2965<\/td>\n",
       "      <td>1.9973<\/td>\n",
       "      <td>0.4096<\/td>\n",
       "      <td>0.3865<\/td>\n",
       "      <td>-0.3381<\/td>\n",
       "      <td>0.6050<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>-0.6721<\/td>\n",
       "      <td>0.3069<\/td>\n",
       "      <td>0.4214<\/td>\n",
       "      <td>0.6709<\/td>\n",
       "      <td>-0.1744<\/td>\n",
       "      <td>0.1103<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5-2<\/th>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>2.3909<\/td>\n",
       "      <td>-0.7401<\/td>\n",
       "      <td>0.1264<\/td>\n",
       "      <td>0.1840<\/td>\n",
       "      <td>0.4573<\/td>\n",
       "      <td>-0.1825<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTSEK10Y Govt Adjusted<\/th>\n",
       "      <td>1.1490<\/td>\n",
       "      <td>0.6452<\/td>\n",
       "      <td>0.1401<\/td>\n",
       "      <td>0.1722<\/td>\n",
       "      <td>0.2719<\/td>\n",
       "      <td>0.2209<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCHF10Y Govt Adjusted<\/th>\n",
       "      <td>-2.0456<\/td>\n",
       "      <td>1.1334<\/td>\n",
       "      <td>0.0926<\/td>\n",
       "      <td>0.1795<\/td>\n",
       "      <td>-0.5139<\/td>\n",
       "      <td>0.3325<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>1.1222<\/td>\n",
       "      <td>-0.1872<\/td>\n",
       "      <td>0.1446<\/td>\n",
       "      <td>0.5330<\/td>\n",
       "      <td>0.2995<\/td>\n",
       "      <td>-0.0668<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5-5<\/th>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>0.1714<\/td>\n",
       "      <td>2.4262<\/td>\n",
       "      <td>0.2839<\/td>\n",
       "      <td>0.5061<\/td>\n",
       "      <td>0.0336<\/td>\n",
       "      <td>0.5920<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTSEK10Y Govt Adjusted<\/th>\n",
       "      <td>2.4985<\/td>\n",
       "      <td>-0.5422<\/td>\n",
       "      <td>0.1416<\/td>\n",
       "      <td>0.2306<\/td>\n",
       "      <td>0.6189<\/td>\n",
       "      <td>-0.1824<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCHF10Y Govt Adjusted<\/th>\n",
       "      <td>0.2843<\/td>\n",
       "      <td>0.6685<\/td>\n",
       "      <td>0.0611<\/td>\n",
       "      <td>0.0976<\/td>\n",
       "      <td>0.0732<\/td>\n",
       "      <td>0.2017<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>0.0720<\/td>\n",
       "      <td>1.2507<\/td>\n",
       "      <td>0.3231<\/td>\n",
       "      <td>0.4087<\/td>\n",
       "      <td>0.0192<\/td>\n",
       "      <td>0.4654<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{},
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"8yxiX4l4zLBPX6NKgbZWcf",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Sheet 2"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"Sheet 2",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "sheet_delimiter":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Appendix: Coherent pair and noncoherent pair comparison"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"IMxak23liryr8eOiwzrFQX",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Training\/testing data split\n",
    "training_testing_Split = '2018-12-31'\n",
    "training_return = tr_dm_net[tr_dm_net.index <= training_testing_Split]\n",
    "testing_return = tr_dm_net[tr_dm_net.index > training_testing_Split]\n",
    "\n",
    "training_price = tr_dm_net_price[tr_dm_net_price.index <= training_testing_Split]\n",
    "testing_price = tr_dm_net_price[tr_dm_net_price.index > training_testing_Split]\n"
   ],
   "execution_count":86,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"rlezeS29ZVpUIjXxUIi306",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "def evaluate_pair_performance(pairs_list, data, window_size, upper_threshold, close_threshold):\n",
    "    pairs_metrics = {}\n",
    "    \n",
    "    for asset1, asset2 in pairs_list:\n",
    "\n",
    "        z_score, spread, returns, cumulative_return, positions = rule_based_strategy_info(data, window_size, upper_threshold, close_threshold, asset1, asset2)\n",
    "\n",
    "        metrics = {\n",
    "            'Cumulative Return': cumulative_return[-1],\n",
    "            # 'Max Drawdown': calculate_max_drawdown(returns),\n",
    "            'Spread Volatility': spread.std(),\n",
    "            'signal_count': len(z_score[abs(z_score) > upper_threshold]),\n",
    "            'avg_deviation': abs(z_score).mean(),\n",
    "            'max_deviation': abs(z_score).max(),\n",
    "            'signal_frequency': len(z_score[abs(z_score) > upper_threshold]) \/ len(z_score),\n",
    "            'Average Trade Return': np.mean(returns[returns != 0])\n",
    "        }\n",
    "\n",
    "        pairs_metrics[(asset1.replace(\"Adjusted Return\",\"\"), asset2.replace(\"Adjusted Return\",\"\"))] = metrics\n",
    "            \n",
    "    return pairs_metrics\n",
    "\n",
    "def compare_coherent_noncoherent(coherent_pair, noncoherent_pair, data, \n",
    "                                 window_size_coherent, upper_threshold_coherent, close_threshold_coherent,\n",
    "                                 window_size_noncoherent, upper_threshold_noncoherent, close_threshold_noncoherent):\n",
    "\n",
    "    coherent_metrics = evaluate_pair_performance(coherent_pair, data, \n",
    "                                               window_size_coherent, upper_threshold_coherent, close_threshold_coherent)\n",
    "    \n",
    "    noncoherent_metrics = evaluate_pair_performance(noncoherent_pair, data, \n",
    "                                                window_size_noncoherent, upper_threshold_noncoherent, close_threshold_noncoherent)\n",
    "    \n",
    "    \n",
    "    return coherent_metrics, noncoherent_metrics\n"
   ],
   "execution_count":87,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"U6rHqOMmm33eTToJDfdJHA",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "window_size_list = [30, 60, 90]\n",
    "upper_threshold_list = [1.0, 1.25, 1.5]\n",
    "close_threshold_list = [0.1, 0.5, 1]\n",
    "\n",
    "coherent_pair, noncoherent_pair = noncoherent_pair_cluster(training_return, training_price)\n",
    "# upper_threshold_coherent=upper_threshold_noncoherent = 1.0\n",
    "# close_threshold_coherent = close_threshold_noncoherent = 0.1\n",
    "# window_size_coherent = window_size_noncoherent = 60\n",
    "\n",
    "\n",
    "upper_threshold_coherent, close_threshold_coherent, window_size_coherent = optimize_parameters(training_return, coherent_pair, window_size_list, upper_threshold_list, close_threshold_list)\n",
    "upper_threshold_noncoherent, close_threshold_noncoherent, window_size_noncoherent = optimize_parameters(training_return, noncoherent_pair, window_size_list, upper_threshold_list, close_threshold_list)\n",
    "\n",
    "coherent_metrics, noncoherent_metrics= compare_coherent_noncoherent(coherent_pair, noncoherent_pair,training_return, \n",
    "                                window_size_coherent, upper_threshold_coherent, close_threshold_coherent,\n",
    "                                window_size_noncoherent, upper_threshold_noncoherent, close_threshold_noncoherent)\n",
    "\n",
    "test_coherent_metrics, test_noncoherent_metrics= compare_coherent_noncoherent(coherent_pair, noncoherent_pair,testing_return, \n",
    "                                window_size_coherent, upper_threshold_coherent, close_threshold_coherent,\n",
    "                                window_size_noncoherent, upper_threshold_noncoherent, close_threshold_noncoherent)\n",
    "\n",
    "\n",
    "coherent_df = pd.DataFrame(coherent_metrics).round(4).T\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAIN COHERENT PAIRS PERFORMANCE\".center(80))\n",
    "print(\"=\"*80)\n",
    "print(coherent_df.to_string())\n",
    "\n",
    "noncoherent_df = pd.DataFrame(noncoherent_metrics).round(4).T\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAIN NONCOHERENT PAIRS PERFORMANCE\".center(80))\n",
    "print(\"=\"*80)\n",
    "print(noncoherent_df.to_string())\n",
    "\n",
    "\n",
    "test_coherent_df = pd.DataFrame(test_coherent_metrics).round(4).T\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST COHERENT PAIRS PERFORMANCE\".center(80))\n",
    "print(\"=\"*80)\n",
    "print(test_coherent_df.to_string())\n",
    "\n",
    "test_noncoherent_df = pd.DataFrame(test_noncoherent_metrics).round(4).T\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST NONCOHERENT PAIRS PERFORMANCE\".center(80))\n",
    "print(\"=\"*80)\n",
    "print(test_noncoherent_df.to_string())"
   ],
   "execution_count":110,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\n",
      "================================================================================\n",
      "                        TRAIN COHERENT PAIRS PERFORMANCE                        \n",
      "================================================================================\n",
      "                                               Cumulative Return  Spread Volatility  signal_count  avg_deviation  max_deviation  signal_frequency  Average Trade Return\n",
      "GTFRF10Y Govt Adjusted GTSEK10Y Govt Adjusted             0.3214             0.0062         201.0         0.7407         5.2811            0.1701                0.0016\n",
      "GTSEK10Y Govt Adjusted GTCHF10Y Govt Adjusted             5.2274             0.0105         219.0         0.7599         4.8665            0.1853                0.0178\n",
      "                       GTDEM10Y Govt Adjusted             0.0361             0.0027         208.0         0.7611         3.9946            0.1760                0.0002\n",
      "GTAUD10Y Govt Adjusted GTNZD10Y Govt Adjusted            -0.0891             0.0058         210.0         0.7613         3.6757            0.1777               -0.0003\n",
      "\n",
      "================================================================================\n",
      "                      TRAIN NONCOHERENT PAIRS PERFORMANCE                       \n",
      "================================================================================\n",
      "                                               Cumulative Return  Spread Volatility  signal_count  avg_deviation  max_deviation  signal_frequency  Average Trade Return\n",
      "GTFRF10Y Govt Adjusted GT10 Govt Adjusted                 0.0409             0.0028         128.0         0.7557         4.2820            0.1083                0.0003\n",
      "GTSEK10Y Govt Adjusted GT10 Govt Adjusted                 0.0217             0.0031         133.0         0.7422         4.1335            0.1125                0.0002\n",
      "                       GTCAD10Y Govt Adjusted             0.0801             0.0034         119.0         0.7437         4.3844            0.1007                0.0007\n",
      "GTCHF10Y Govt Adjusted GTCAD10Y Govt Adjusted             0.5930             0.0317         122.0         0.7427         7.6047            0.1032                0.0051\n",
      "GTAUD10Y Govt Adjusted GTJPY10Y Govt Adjusted            -0.9863             0.0719         122.0         0.6761         7.5458            0.1032               -0.0151\n",
      "\n",
      "================================================================================\n",
      "                        TEST COHERENT PAIRS PERFORMANCE                         \n",
      "================================================================================\n",
      "                                               Cumulative Return  Spread Volatility  signal_count  avg_deviation  max_deviation  signal_frequency  Average Trade Return\n",
      "GTFRF10Y Govt Adjusted GTSEK10Y Govt Adjusted            -0.1513             0.0033         269.0         0.7744         4.4130            0.1808               -0.0006\n",
      "GTSEK10Y Govt Adjusted GTCHF10Y Govt Adjusted             0.0176             0.0035         300.0         0.7709         3.4990            0.2016                0.0001\n",
      "                       GTDEM10Y Govt Adjusted             0.1288             0.0030         284.0         0.7737         3.4550            0.1909                0.0005\n",
      "GTAUD10Y Govt Adjusted GTNZD10Y Govt Adjusted             0.1602             0.0057         295.0         0.7829         3.8547            0.1983                0.0006\n",
      "\n",
      "================================================================================\n",
      "                       TEST NONCOHERENT PAIRS PERFORMANCE                       \n",
      "================================================================================\n",
      "                                               Cumulative Return  Spread Volatility  signal_count  avg_deviation  max_deviation  signal_frequency  Average Trade Return\n",
      "GTFRF10Y Govt Adjusted GT10 Govt Adjusted                 0.0352             0.0036         180.0         0.7635         6.3989            0.1210                0.0002\n",
      "GTSEK10Y Govt Adjusted GT10 Govt Adjusted                 0.1029             0.0039         184.0         0.7816         4.4333            0.1237                0.0006\n",
      "                       GTCAD10Y Govt Adjusted             0.3543             0.0046         184.0         0.7921         3.9816            0.1237                0.0017\n",
      "GTCHF10Y Govt Adjusted GTCAD10Y Govt Adjusted             0.2934             0.0046         169.0         0.7761         4.2420            0.1136                0.0016\n",
      "GTAUD10Y Govt Adjusted GTJPY10Y Govt Adjusted            -0.2425             0.6757         187.0         0.7152         7.5820            0.1257                0.3194\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"IHHD3HGgCDxC9mzztO1Bxd",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[],
   "report_row_ids":[],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}