{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "pip install kneed"
   ],
   "execution_count":118,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Requirement already satisfied: kneed in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (0.8.5)\r\n",
      "Requirement already satisfied: numpy>=1.14.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from kneed) (1.24.3)\r\n",
      "Requirement already satisfied: scipy>=1.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from kneed) (1.9.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"OqNR8qBgSZja8OlpWefoYI",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "pip install openpyxl"
   ],
   "execution_count":119,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Requirement already satisfied: openpyxl in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (3.1.5)\r\n",
      "Requirement already satisfied: et-xmlfile in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from openpyxl) (2.0.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"XUDcjyQe2BBBhi4xqGwN7c",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import torch"
   ],
   "execution_count":120,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"hs7o5W3KFddgkUbS93t7Wa",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from collections import deque\n",
    "import random\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple, deque\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import euclidean"
   ],
   "execution_count":121,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"9PPUdmkbRq5K3aZefIg9Bu",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Part 1: Data Preparation \n",
    "### Adjust the bond prices to mitigate the impact of the benchmark bond roll."
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"FxbEU0b1iwFkCFcDStcftK",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "tr_dm = pd.read_excel('GENERIC BOND PRICE.xlsx', sheet_name='DM_PRICE')\n",
    "tr_dm.Dates = pd.to_datetime(tr_dm.Dates)\n",
    "tr_dm = tr_dm.set_index('Dates')"
   ],
   "execution_count":122,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"na8Z7HraSCUpsgtAhiH9El",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def calculate_dirty_price(clean_price, coupon, days_since_last_coupon):\n",
    "    daily_coupon = coupon \/ 365  \n",
    "    accrued_interest = daily_coupon * days_since_last_coupon\n",
    "    return clean_price + accrued_interest\n",
    "\n",
    "def calculate_days_since_last_coupon(date, last_coupon_date):\n",
    "    return (date - last_coupon_date).days\n",
    "\n",
    "def find_first_coupon_date(coupon_series):\n",
    "    coupon_changes = coupon_series.diff().dropna()\n",
    "    if len(coupon_changes) > 0:\n",
    "        first_change_date = coupon_changes.index[0]\n",
    "        return first_change_date - pd.Timedelta(days=180)  # Assume coupon paid 6 months before the change\n",
    "    else:\n",
    "        return coupon_series.index[0] \n",
    "    "
   ],
   "execution_count":123,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"qCpLGNyRVbpXvM2HxK3bzl",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "dirty_price_series = {}\n",
    "for column in tr_dm.columns:\n",
    "    if column.endswith('Govt'):\n",
    "        clean_price_series = tr_dm[column]\n",
    "        coupon_series = tr_dm[f\"{column} CPN\"]\n",
    "\n",
    "        first_coupon_date = find_first_coupon_date(coupon_series)\n",
    "        last_coupon_date = first_coupon_date\n",
    "        current_coupon = coupon_series.iloc[0]\n",
    "        \n",
    "        dirty_prices = []\n",
    "        \n",
    "        for date, clean_price in clean_price_series.items():\n",
    "            if coupon_series[date] != current_coupon:\n",
    "                last_coupon_date = date - pd.Timedelta(days=180)\n",
    "                current_coupon = coupon_series[date]\n",
    "            \n",
    "            days_since_last_coupon = calculate_days_since_last_coupon(date, last_coupon_date)\n",
    "            \n",
    "            dirty_price = calculate_dirty_price(clean_price, current_coupon, days_since_last_coupon)\n",
    "            dirty_prices.append(dirty_price)\n",
    "\n",
    "            if days_since_last_coupon >= 180:\n",
    "                last_coupon_date = date\n",
    "\n",
    "        tr_dm[f\"{column}_Dirty\"] = pd.Series(dirty_prices, index=clean_price_series.index)"
   ],
   "execution_count":124,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"I9Td6deyEsn0KKhefI4Gkm",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "for bond_col in tr_dm.columns:\n",
    "    if bond_col.endswith('Dirty'): \n",
    "        coupon_col = bond_col.replace('Govt_Dirty', 'Govt CPN')\n",
    "        bond_col = bond_col.replace('_Dirty','')\n",
    "        \n",
    "        tr_dm[f\"{bond_col} Adjusted\"] = tr_dm[bond_col]\n",
    "        \n",
    "        coupon_changes = tr_dm[coupon_col].diff().fillna(0) != 0\n",
    "\n",
    "        for change_date in tr_dm.index[coupon_changes]:\n",
    "\n",
    "            price_on_change = tr_dm.loc[change_date, bond_col]\n",
    "            \n",
    "            previous_price = tr_dm.loc[tr_dm.index[tr_dm.index.get_loc(change_date) - 1], bond_col]\n",
    "            \n",
    "            price_diff = price_on_change - previous_price\n",
    "            \n",
    "            tr_dm.loc[change_date:, f\"{bond_col} Adjusted\"] -= price_diff\n",
    "\n",
    "        tr_dm[f\"{bond_col} Adjusted Return\"] = tr_dm[f\"{bond_col} Adjusted\"].pct_change()\n",
    "\n",
    "\n",
    "# col_adj = [i for i in tr_dm.columns if (i.endswith('Adjusted') or i.endswith('Adjusted Return'))]\n",
    "\n",
    "col_adj_price = [i for i in tr_dm.columns if i.endswith('Adjusted')]\n",
    "\n",
    "col_adj_return = [i for i in tr_dm.columns if i.endswith('Adjusted Return')]\n",
    "\n",
    "tr_dm_net = tr_dm[col_adj_return].fillna(0)\n",
    "\n",
    "tr_dm_net_price = tr_dm[col_adj_price].fillna(0)"
   ],
   "execution_count":125,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"s5S2f174w5nndoxNp8Ls5U",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Part 3: Identify Correlated Assets (Developed Market)\n",
    "### Step1 : PCA (cluster by the first principal component)"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"TuVft2K7E4OGuQ0C6RGmSQ",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from statsmodels.tsa.stattools import coint\n",
    "\n",
    "def test_cointegration_in_clusters(data, cluster_dict):\n",
    "\n",
    "    cointegrated_pairs = []\n",
    "    for cluster_num in cluster_dict:\n",
    "        asset_names = cluster_dict[cluster_num]\n",
    "        asset_names = [i.replace(' Return', '') for i in asset_names]\n",
    "        \n",
    "        # Loop through each pair of assets in the cluster\n",
    "        for i in range(len(asset_names)):\n",
    "            for j in range(i + 1, len(asset_names)):\n",
    "                asset1 = asset_names[i]\n",
    "                asset2 = asset_names[j]\n",
    "             \n",
    "                series1 = data[asset1]\n",
    "                series2 = data[asset2]\n",
    "                \n",
    "                # Perform the Engle-Granger cointegration test\n",
    "                coint_t, p_value, _ = coint(series1, series2)\n",
    "                \n",
    "                # set a higher significant level (0.2) to avoid missing potential relationship\n",
    "                if p_value < 0.2:  \n",
    "                    cointegrated_pairs.append([asset1,asset2])\n",
    "                else:\n",
    "                    pass\n",
    "                    # print(f\"  {asset1} and {asset2} are NOT cointegrated (p-value: {p_value:.4f})\")\n",
    "\n",
    "    return cointegrated_pairs\n"
   ],
   "execution_count":126,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"OAaLctWBqKuHggcbLfy7DD",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "def noncoherent_pair_cluster(data, data_price): # input: return data, price data\n",
    "    # Step 1: Cluster by Principal component 1\n",
    "    scaler = StandardScaler()\n",
    "    asset_returns = pd.DataFrame(scaler.fit_transform(data), columns= data.columns)\n",
    "\n",
    "\n",
    "    # Calculate the loadings of bond returns on PCs\n",
    "    K = 1\n",
    "    pca = PCA(n_components=K)\n",
    "    pca.fit(asset_returns)\n",
    "    loadings = pca.components_.T\n",
    "\n",
    "    wcss = []\n",
    "    for k in range(1, 10):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(loadings)\n",
    "        # Inertia: Sum of squared distances to closest cluster center\n",
    "        wcss.append(kmeans.inertia_)  \n",
    "        \n",
    "    # Use the KneeLocator to detect the elbow point\n",
    "    kneedle = KneeLocator(range(1, 10), wcss, S=1.0, curve='convex', direction='decreasing')\n",
    "\n",
    "    # Get the optimal number of clusters\n",
    "    optimal_clusters = kneedle.elbow\n",
    "\n",
    "\n",
    "    # Clustering in the principal component space and using K-means to cluster different govt bonds\n",
    "    kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(loadings)\n",
    "    asset_names = asset_returns.columns\n",
    "\n",
    "    cluster_dic = {}\n",
    "    for cluster in range(optimal_clusters):\n",
    "        cluster_assets = asset_names[clusters == cluster]\n",
    "        cluster_dic[cluster + 1] =cluster_assets\n",
    "\n",
    "\n",
    "    # Step 2: Find cointegration pairs\n",
    "    cointegrated_pairs = test_cointegration_in_clusters(data_price, cluster_dic)\n",
    "\n",
    "    # Step 3: Exclude pairs have similar PC2 and PC3\n",
    "    K = 3\n",
    "    pca = PCA(n_components=K)\n",
    "    pca.fit(asset_returns)\n",
    "    loadings = pca.components_.T\n",
    "\n",
    "    loadings_df = pd.DataFrame(loadings, columns = ['PC1','PC2','PC3'], index = data.columns)\n",
    "\n",
    "    threshold_pc2 = 0.01 \n",
    "    threshold_pc3 = 0.01\n",
    "\n",
    "    coherent_pair = []\n",
    "    noncoherent_pair = []\n",
    "\n",
    "    for i in range(len(cointegrated_pairs)):\n",
    "        asset1 = cointegrated_pairs[i][0]\n",
    "        asset2 = cointegrated_pairs[i][1]\n",
    "        \n",
    "        bond1_loadings_pc2 = loadings_df.loc[f\"{asset1} Return\", 'PC2'] \n",
    "        bond2_loadings_pc2 = loadings_df.loc[f\"{asset2} Return\", 'PC2'] \n",
    "        \n",
    "        bond1_loadings_pc3 = loadings_df.loc[f\"{asset1} Return\", 'PC3']\n",
    "        bond2_loadings_pc3 = loadings_df.loc[f\"{asset2} Return\", 'PC3']  \n",
    "        \n",
    "        # Euclidean distance between PC2 and PC3 loadings\n",
    "        distance_pc2 = euclidean([bond1_loadings_pc2], [bond2_loadings_pc2])\n",
    "        distance_pc3 = euclidean([bond1_loadings_pc3], [bond2_loadings_pc3])\n",
    "        \n",
    "        if distance_pc2 > threshold_pc2 and distance_pc3 > threshold_pc3:\n",
    "            noncoherent_pair.append((asset1, asset2))\n",
    "        else:\n",
    "            coherent_pair.append((asset1, asset2))\n",
    "            \n",
    "\n",
    "    return noncoherent_pair\n"
   ],
   "execution_count":127,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"YTZ4KjUXOOGggR98zwiv3r",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Part 4: Naiive Rule-based Trading Algorithm"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"Nqxt5EA3IH5wClIWGl2rFr",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "The code below implements a rule-based pair trading strategy that is based on the 2nd principal component loadings of the asset pair to construct a market-neutral spread.\n",
    "\n",
    "Key Steps:\n",
    "1. Rolling PCA Calculation:\n",
    "\n",
    "Option 1: PCA is applied on the returns of only two selected assets. In this case, the first principal component (PC1) represents the common trend between the two selected assets.\n",
    "\n",
    "Option 2: PCA can be applied to all 11 bonds, which would make the PC1 represent the broader market trend for all treasury bonds. PC2 represents the specific factors that diverge from the broader market, allowing for more targeted trading opportunities.\n",
    "\n",
    "2. Rolling Loadings:\n",
    "\n",
    "The PCA loadings are calculated on a rolling basis to avoid look-ahead bias over time. The strategy focuses on the loadings for the second principal component (PC2), which reflects the bond-specific factors that are relatively insensitive (orthogonal) to broader market movements captured by PC1.\n",
    "The code extracts the rolling loadings of the selected assets on PC2 and uses these loadings to construct the spread.\n",
    "\n",
    "3. Spread Construction:\n",
    "\n",
    "The spread is calculated as a linear combination of the two assets' returns weighted by their PC2 loadings.\n",
    "Then the weights are normalized based on the total absolute weight of the two assets to ensure that the portfolio remains balanced.\n",
    "\n",
    "$ \\text{Spread}  = w1 * \\text{Asset 1 Return} - w2 * \\text{Asset 2 Return}$\n",
    "\n",
    "$ w1 = 1 $\n",
    "\n",
    "\n",
    "$ w2 = w1 * \\frac{\\sigma 1}{\\sigma 2} * \\frac{PC loading Asset 1}{PC Loading Asset 2} $\n",
    "\n",
    "\n",
    "\n",
    "1. Trading Signals:\n",
    "\n",
    "Buy Signal: Generated when the z-score of the spread (number of standard deviations the spread deviates from its rolling mean) falls below a specified lower threshold. This implies the spread has diverged significantly, and the strategy goes long on the spread, expecting a reversal.\n",
    "Sell Signal: Generated when the z-score rises above the upper threshold, indicating the spread has widened significantly. The strategy goes short on the spread, expecting a convergence.\n",
    "Exit Signal: The strategy closes the positions when the spread reverts to a level closer to the mean, as defined by a close threshold.\n",
    "\n",
    "5. Z-Score and Thresholds:\n",
    "\n",
    "The z-score is calculated based on the rolling mean and rolling standard deviation of the spread. This z-score is used to quantify the divergence of the spread from its historical average.\n",
    "The thresholds (upper, lower, and close) dictate when the strategy enters and exits positions.\n",
    "\n",
    "6. Performance Evaluation:\n",
    "\n",
    "The code tracks the cumulative returns of the pair trading strategy over time. It shifts the positions by one day to avoid look-ahead bias when calculating the returns for the next day.\n",
    "The final cumulative returns are plotted to visualize the strategy's performance for the selected asset pair."
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"EtKheX28n7YrMDQf952kP1",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def rolling_pca_loadings(data, window_size, num_components=2):\n",
    "    rolling_loadings = []\n",
    "    \n",
    "    for i in range(window_size, len(data) + 1):\n",
    "        window_data = data[i - window_size:i]\n",
    "        pca = PCA(n_components=num_components)\n",
    "        pca.fit(window_data)\n",
    "        loadings = pca.components_.T  \n",
    "        rolling_loadings.append(loadings)\n",
    "        \n",
    "    return np.array(rolling_loadings)\n",
    "\n",
    "def diff_sign_pc_loadings(data, window_size):\n",
    "    loadings = rolling_pca_loadings(data, window_size, num_components=2)\n",
    "    result = []\n",
    "    for matrix in loadings:\n",
    "        first_col = matrix[:, 0]\n",
    "        second_col = matrix[:, 1]\n",
    "        \n",
    "        if np.sign(first_col[0]) == np.sign(first_col[1]):\n",
    "            result.append(first_col)\n",
    "        else:\n",
    "            result.append(second_col)\n",
    "    \n",
    "    result_array = np.array(result)\n",
    "    \n",
    "    return result_array"
   ],
   "execution_count":128,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"I5JpXbpiVv7hdJGf73whLK",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Non-coherent pair\n",
    "def rule_based_strategy(data, window_size, upper_threshold,close_threshold, asset1,asset2):\n",
    "\n",
    "    # 1. Rolling PCA Calculation:\n",
    "    # option1: apply pca on two assets: pc1 represents the common trend between asset1 and asset 2 only\n",
    "    selected_asset_returns = data[[f'{asset1}', f'{asset2}']]\n",
    "    \n",
    "    # 2. Rolling Loadings:\n",
    "    rolling_loadings = diff_sign_pc_loadings(selected_asset_returns, window_size)\n",
    "\n",
    "    # rolling_pc1_loadings = rolling_loadings[:, :, 0]  # First component loadings\n",
    "    # rolling_pc2_loadings = rolling_loadings[:, :, 1]  # Second component loadings\n",
    "    \n",
    "    \n",
    "    pc_loading_asset1 = rolling_loadings[:, 0] \n",
    "    pc_loading_asset2 = rolling_loadings[:, 1] \n",
    "\n",
    "    # 3. Spread Construction:\n",
    "    \n",
    "    sigma_asset1 = data[f'{asset1}'].rolling(window=window_size).std().dropna()\n",
    "    sigma_asset2 = data[f'{asset2}'].rolling(window=window_size).std().dropna()\n",
    "    pc_loading_asset1 = pd.Series(pc_loading_asset1, index = sigma_asset1.index)\n",
    "    pc_loading_asset2 = pd.Series(pc_loading_asset2, index = sigma_asset2.index)\n",
    "\n",
    "    sigma_ratio = sigma_asset1 \/ sigma_asset2\n",
    "    \n",
    "    w1 = 1\n",
    "    w2 = (w1 * sigma_ratio * pc_loading_asset1)\/pc_loading_asset2\n",
    "    \n",
    "    spread = w1 * data[f'{asset1} Return'] - w2 * data[f'{asset2} Return']\n",
    "\n",
    "    # 4. Trading Signals:\n",
    "    rolling_mean = spread.rolling(window=window_size).mean()\n",
    "    rolling_std = spread.rolling(window=window_size).std()\n",
    "\n",
    "    # 5. Z-Score and Thresholds:\n",
    "    z_score = (spread - rolling_mean) \/ rolling_std\n",
    "    \n",
    "    lower_threshold = - upper_threshold\n",
    "    \n",
    "    positions = pd.DataFrame(index=data.index, columns=['Position','Holdings_w1','Holdings_w2'])\n",
    "    \n",
    "    # Enter signal (spread deviates from the mean)\n",
    "    positions['Position'] = np.where(z_score > upper_threshold, -1, 0)\n",
    "    positions['Position'] = np.where(z_score < lower_threshold, 1, positions['Position'])\n",
    "    \n",
    "    # Exit signal (spread reverts to the mean)\n",
    "    positions['Position'] = np.where((z_score > - close_threshold) & (positions['Position'] == 1), 0, positions['Position'])\n",
    "    positions['Position'] = np.where((z_score < close_threshold) & (positions['Position'] == -1), 0, positions['Position'])\n",
    "    \n",
    "    positions['Holdings_w1'] = positions['Position'] * w1\n",
    "    positions['Holdings_w2'] = positions['Position'] * w2\n",
    "\n",
    "\n",
    "    # 6. Performance Evaluation:\n",
    "    positions_shifted = positions.shift(1)  \n",
    "    returns = positions_shifted['Holdings_w1'] * data[f'{asset1}'] + positions_shifted['Holdings_w2'] * data[f'{asset2}']\n",
    "    initial_investment = 1\n",
    "    cumulative_returns = (1+ returns).cumprod() -1\n",
    "\n",
    "    return cumulative_returns[-1]"
   ],
   "execution_count":129,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"yIwOIiFivIeBnrCHKphv3n",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### Grid search for the optimal parameters"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"ixNDbv1uRxqyLsDNxbEAFw",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def optimize_parameters(data, noncoherent_pair, window_size_list, upper_threshold_list, close_threshold_list):\n",
    "\n",
    "    param_results = {}\n",
    "    pair_results = {}\n",
    "    \n",
    "    # Try each parameter combination\n",
    "    for window_size, upper_threshold, close_threshold in itertools.product(\n",
    "            window_size_list, upper_threshold_list, close_threshold_list):\n",
    "        \n",
    "        if close_threshold >= upper_threshold:\n",
    "            continue\n",
    "            \n",
    "        returns = []\n",
    "        pair_details = []\n",
    "        \n",
    "        for asset_pair in noncoherent_pair:\n",
    "            asset1 = asset_pair[0]#.replace(' Adjusted Return', '')\n",
    "            asset2 = asset_pair[1]#.replace(' Adjusted Return', '')\n",
    "            \n",
    "            # Get return for this pair with current parameters\n",
    "            result = rule_based_strategy(data, window_size, upper_threshold, close_threshold, asset1, asset2)\n",
    "            returns.append(result)\n",
    "            \n",
    "            pair_details.append({'asset1': asset1, 'asset2': asset2, 'return': result})\n",
    "        \n",
    "        # Store average return for this parameter combination\n",
    "        param_key = (window_size, upper_threshold, close_threshold)\n",
    "        param_results[param_key] = {'avg_return': np.mean(returns),'pair_details': pair_details}\n",
    "\n",
    "    \n",
    "    # Find best parameter combination\n",
    "    best_params = max(param_results.items(), key=lambda x: x[1]['avg_return'])\n",
    "    window_size, upper_threshold, close_threshold = best_params[0]\n",
    "    \n",
    "    \n",
    "    return upper_threshold, close_threshold, window_size\n"
   ],
   "execution_count":130,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"XRsls6Nfsnf8IH9smFPzm1",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Part 5: Reinforcement Learning Based Strategy"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"8u7rXTvSP7fwoHt4ULmkGb",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "To enhance the existing rule-based strategy for pair trading using a Deep Q-Network (DQN), we can replace the rule-based signals with a reinforcement learning (RL) approach. The purpose for RL step is to find 'when' to trade and 'how much' to trade by interacting with observation space, action space and reward space.\n",
    "\n",
    "Key Points:\n",
    "\n",
    "Teachnique: DQN Strategy\n",
    "\n",
    "Dynamic Pair Selection & Training Process\n",
    "1. Formation Period (Year T): Select correlated pairs using PCA\n",
    "2. Training Period (Year T+1): Train RL agent on selected pairs\n",
    "3. Testing Period (Year T+2): Test agent on newly generated pairs\n",
    "4. Repeat process by rolling forward one year for robust validation\n",
    "\n",
    "![image.png](attachment:.\/attachment:853841c4-393a-4b7c-870b-290257aa81f2.png)\n",
    "\n",
    "Model Architecture\n",
    "1. Deep Q-Network (DQN) for automated trading decisions \n",
    "2. State space includes normalized spread, z-score, position metrics\n",
    "3. Action space: Long (1), Neutral (0), Short (-1) positions\n",
    "4. Reward = Return - beta * (RL action - rule-based strategy action)\n",
    "\n",
    "Training Process:\n",
    "1. the agent learns optimal entry and exit points through extensive episodes with different pairs and market conditions\n",
    "2. Set the network with highest reward as target network, agent continuously learns to match or exceed this taret network performance\n",
    "3. the agent develop resilience to both regime changes and switching between different asset pairs, making it truly adaptive to market dynamics."
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"1t1thSUrnrGfT0e7KT2s4B",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# defines a new class called DQN that inherits from PyTorch's nn.Module. \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# todo: to be fine-tuned\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size,activation, hidden_sizes=[128,128], dropout_rate=0.2):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if activation == 'relu':\n",
    "            act_fn = nn.ReLU()\n",
    "        elif activation == 'leaky_relu':\n",
    "            act_fn = nn.LeakyReLU(0.01)\n",
    "        elif activation == 'elu':\n",
    "            act_fn = nn.ELU()\n",
    "        elif activation == 'selu':\n",
    "            act_fn = nn.SELU()\n",
    "        elif activation == 'tanh':\n",
    "            act_fn = nn.Tanh()\n",
    "\n",
    "    \n",
    "        # Input layer\n",
    "        self.layers.append(nn.Linear(state_size, hidden_sizes[0]))\n",
    "        self.layers.append(nn.LayerNorm(hidden_sizes[0]))\n",
    "        self.layers.append(act_fn)\n",
    "        self.layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            self.layers.append(nn.LayerNorm(hidden_sizes[i]))\n",
    "            self.layers.append(act_fn)\n",
    "            self.layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        # Output layer\n",
    "        self.layers.append(nn.Linear(hidden_sizes[-1], action_size))\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = state\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "# creates a named tuple to store experience replays. a convenient way to group related data.\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state', 'done'))"
   ],
   "execution_count":131,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"LUtuzOYD0iR1wibeNKYcJd",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ],
   "execution_count":132,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"smThOdR5upzpg1qwIoAcE3",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size,active_func, learning_rate=1e-3):\n",
    "        self.active_func= active_func\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = ReplayBuffer(10000) # a replay buffer with a capacity of 10,000 experiences\n",
    "        self.gamma = 0.95    # discount factor\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = learning_rate\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.policy_net = DQN(state_size, action_size,active_func).to(self.device)\n",
    "        self.target_net = DQN(state_size, action_size,active_func).to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate) #update for policy network's weight\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='max', \n",
    "                                                            factor=0.1, patience=10)\n",
    "        \n",
    "    def act(self, state):\n",
    "        if random.random() <= self.epsilon: # exploration (random act)\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        with torch.no_grad(): # exploitation: follow policy network\n",
    "            state = torch.FloatTensor(state).unsqueeze(0).to(self.device)  \n",
    "            action_values = self.policy_net(state)\n",
    "            return action_values.max(1)[1].item()\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.push(state, action, reward, next_state, done) # add new experience to replay buffer\n",
    "\n",
    "    def learn(self):\n",
    "\n",
    "        if len(self.memory) < self.batch_size: # check if enough space in buffer\n",
    "            return\n",
    "        \n",
    "        transitions = self.memory.sample(self.batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        \n",
    "        state_batch = torch.FloatTensor(batch.state).to(self.device)\n",
    "        action_batch = torch.LongTensor(batch.action).unsqueeze(1).to(self.device)\n",
    "        reward_batch = torch.FloatTensor(batch.reward).to(self.device)\n",
    "        next_state_batch = torch.FloatTensor(np.array(batch.next_state)).to(self.device)\n",
    "        \n",
    "        # pass our batch of states through our policy network to get Q-values for all actions. \n",
    "        # use gather to select only the Q-values for the actions that were actually taken. This gives us our current estimate of the Q-values for our sampled state-action pairs\n",
    "        current_q_values = self.policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # For each non-terminal next state, we compute the maximum Q-value using our target network. \n",
    "        # We use the target network (which is updated less frequently) to provide a more stable target for learning.\n",
    "        next_states = torch.FloatTensor([s for s in batch.next_state if s is not None]).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            next_actions = self.policy_net(next_states).max(1)[1]\n",
    "            next_state_values = self.target_net(next_states).gather(1, next_actions.unsqueeze(1))\n",
    "\n",
    "        # expected (target) Q-values using the Bellman equation.\n",
    "        expected_q_values = (next_state_values * self.gamma) + reward_batch\n",
    "        \n",
    "        # Weighted loss\n",
    "        loss = F.smooth_l1_loss(current_q_values, expected_q_values)\n",
    "\n",
    "        # compute the gradients of the loss with respect to our network parameters, and then update our network parameters (weights and bias) to minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    # every 10 episode, we will copy weights from training policy network to target network\n",
    "    def update_target_net(self):\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "    # as we have more training samples, we don't need to explore too often\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n"
   ],
   "execution_count":133,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"gaC4FLYS2FDxpOeI65S98D",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "class MultiPairTradingEnv:\n",
    "    def __init__(self, asset_returns_raw, pair_list, upper_threshold, close_threshold, window_size, beta):\n",
    "        self.asset_returns_raw = asset_returns_raw\n",
    "        self.pair_list = pair_list  \n",
    "        self.window_size = window_size\n",
    "        self.upper_threshold = upper_threshold\n",
    "        self.close_threshold = close_threshold\n",
    "        self.beta = beta\n",
    "        self.action_space = [-1, 0, 1]\n",
    "        \n",
    "        # Initialize spreads for all pairs\n",
    "        self.spreads = {}\n",
    "        self.w2s = {}\n",
    "        for asset1, asset2 in pair_list:\n",
    "            spread, w2 = self._calculate_spread(asset1, asset2)\n",
    "            self.spreads[(asset1, asset2)] = spread\n",
    "            self.w2s[(asset1, asset2)] = w2\n",
    "        \n",
    "        # Initialize training variables\n",
    "        self.reset()\n",
    "\n",
    "    def _calculate_spread(self, asset1, asset2):\n",
    "        \"\"\"Calculate spread for a given pair\"\"\"\n",
    "        selected_asset_returns = self.asset_returns_raw[[f'{asset1} Return', f'{asset2} Return']]\n",
    "        \n",
    "        rolling_loadings = diff_sign_pc_loadings(selected_asset_returns, self.window_size)\n",
    "        pc_loading_asset1 = rolling_loadings[:, 0]\n",
    "        pc_loading_asset2 = rolling_loadings[:, 1]\n",
    "        \n",
    "        sigma_asset1 = self.asset_returns_raw[f'{asset1} Return'].rolling(window=self.window_size).std().dropna()\n",
    "        sigma_asset2 = self.asset_returns_raw[f'{asset2} Return'].rolling(window=self.window_size).std().dropna()\n",
    "        \n",
    "        pc_loading_asset1 = pd.Series(pc_loading_asset1, index=sigma_asset1.index)\n",
    "        pc_loading_asset2 = pd.Series(pc_loading_asset2, index=sigma_asset2.index)\n",
    "        sigma_ratio = sigma_asset1 \/ sigma_asset2\n",
    "        \n",
    "        w1 = 1\n",
    "        w2 = (w1 * sigma_ratio * pc_loading_asset2) \/ pc_loading_asset1\n",
    "        total_weight = abs(w1) + abs(w2)\n",
    "        w1 = w1 \/ total_weight\n",
    "        w2 = w2 \/ total_weight\n",
    "\n",
    "        spread = w1 * self.asset_returns_raw[f'{asset1} Return'] - w2 * self.asset_returns_raw[f'{asset2} Return']\n",
    "        \n",
    "        return spread, w2\n",
    "\n",
    "    def reset(self,ifbacktest = False, pair = []):\n",
    "        # Randomly select a pair\n",
    "        if ifbacktest:\n",
    "            self.current_pair = pair\n",
    "        else:\n",
    "            self.current_pair = random.choice(self.pair_list)\n",
    "        self.asset1, self.asset2 = self.current_pair\n",
    "        \n",
    "        # Get spread and w2 for selected pair\n",
    "        self.spread = self.spreads[self.current_pair]\n",
    "        self.w2 = self.w2s[self.current_pair]\n",
    "        \n",
    "        # Reset position and portfolio\n",
    "        self.position = 0\n",
    "        self.previous_position = 0\n",
    "        self.portfolio_value = 1\n",
    "        self.steps_taken = 0\n",
    "        self.cumulative_return = [self.portfolio_value]\n",
    "        # Reset tracking variables\n",
    "        self.portfolio_start_value = self.portfolio_value\n",
    "        self.last_position_change = None\n",
    "        self.position_start_value = None\n",
    "        self.return_list = []\n",
    "        self.action_history = []\n",
    "        self.reward = 0\n",
    "        \n",
    "        self.current_step = self.window_size\n",
    "        \n",
    "        return self._get_normalized_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.steps_taken += 1\n",
    "        self.previous_position = self.position\n",
    "        new_position = self.action_space[action]\n",
    "        \n",
    "        # Handle position changes\n",
    "        portfolio_reward = 0\n",
    "        if new_position != 0 and self.previous_position == 0:\n",
    "            self.last_position_change = self.current_step\n",
    "            self.position_start_value = self.portfolio_value\n",
    "        elif new_position == 0 and self.previous_position != 0:\n",
    "            self.last_position_change = None\n",
    "            self.position_start_value = None\n",
    "            portfolio_reward = self._calculate_portfolio_reward()\n",
    "\n",
    "        self.position = new_position\n",
    "        \n",
    "        # Calculate rewards\n",
    "        spread_return = self._calculate_immediate_reward()\n",
    "        baseline_action = self._get_baseline_action()\n",
    "        deviation_penalty = self.beta * abs(action - baseline_action)\n",
    "        self.reward = portfolio_reward - deviation_penalty\n",
    "\n",
    "        # Update portfolio value\n",
    "        self.return_list.append(1 + spread_return)\n",
    "        self.cumulative_return = np.cumprod(self.return_list) -1\n",
    "        self.portfolio_value = self.cumulative_return[-1]\n",
    "        \n",
    "        # Store action\n",
    "        self.action_history.append({\n",
    "            'step': self.current_step,\n",
    "            'pair': self.current_pair,\n",
    "            'position': self.position,\n",
    "            'reward': self.reward,\n",
    "            'spread_return': spread_return,\n",
    "            'portfolio_value': self.portfolio_value,\n",
    "            'cumulative_return': self.cumulative_return\n",
    "        })\n",
    "        \n",
    "        # Advance step\n",
    "        self.current_step += 1\n",
    "        \n",
    "        # Episode ends after 1000 steps or at end of data\n",
    "        done = self.current_step >= len(self.spread) - 1\n",
    "        \n",
    "        # Close position at end of episode\n",
    "        if done and self.position != 0:\n",
    "            self.position = 0\n",
    "            portfolio_reward = self._calculate_portfolio_reward()\n",
    "            self.reward += portfolio_reward\n",
    "        \n",
    "        return self._get_normalized_state(), self.reward, done, {\n",
    "            'pair': self.current_pair,\n",
    "            'portfolio_value': self.portfolio_value,\n",
    "            'spread_return': spread_return,\n",
    "            'deviation_penalty': deviation_penalty\n",
    "        }\n",
    "\n",
    "    def _get_normalized_state(self):\n",
    "        \"\"\"Get normalized state representation\"\"\"\n",
    "        spread = self.spread.iloc[self.current_step]\n",
    "        z_score = self._calculate_z_score(spread)\n",
    "        \n",
    "        # Normalize spread using recent window\n",
    "        window = self.spread.iloc[max(0, self.current_step-100):self.current_step+1]\n",
    "        norm_spread = spread \/ np.std(window)\n",
    "        \n",
    "        # Normalize position duration and profit\n",
    "        position_duration = 0 if self.last_position_change is None else self.current_step - self.last_position_change\n",
    "        norm_duration = np.clip(position_duration \/ 100, 0, 1)\n",
    "        \n",
    "        position_profit = 0 if self.position_start_value is None else (self.portfolio_value - self.position_start_value) \/ self.position_start_value\n",
    "        norm_profit = np.clip(position_profit, -1, 1)\n",
    "        \n",
    "        return np.array([\n",
    "            self.position,  # Already normalized (-1 to 1)\n",
    "            norm_spread,\n",
    "            z_score,  # Normalize z-score\n",
    "            norm_duration,\n",
    "            norm_profit\n",
    "        ])\n",
    "\n",
    "    def _calculate_z_score(self, spread):\n",
    "        window = self.spread.iloc[self.current_step-self.window_size:self.current_step]\n",
    "        return (spread - window.mean()) \/ window.std()\n",
    "\n",
    "    def _calculate_portfolio_reward(self):\n",
    "        if self.position_start_value is None:\n",
    "            return 0\n",
    "        return (self.portfolio_value - self.position_start_value) \/ self.position_start_value\n",
    "\n",
    "    def _calculate_immediate_reward(self):\n",
    "        asset1_return = self.asset_returns_raw[f'{self.asset1} Return'].iloc[self.current_step]\n",
    "        asset2_return = self.asset_returns_raw[f'{self.asset2} Return'].iloc[self.current_step]\n",
    "        prev_index = self.asset_returns_raw.index[self.current_step-1]\n",
    "        w2_prev = self.w2.loc[prev_index]\n",
    "        \n",
    "        spread_return = asset1_return - w2_prev * asset2_return\n",
    "\n",
    "        \n",
    "        return self.previous_position * spread_return\n",
    "    \n",
    "    def _get_baseline_action(self):\n",
    "        z_score = self._calculate_z_score(self.spread.iloc[self.current_step])\n",
    "        lower_threshold = -1 * self.upper_threshold\n",
    "        \n",
    "        if z_score > self.upper_threshold and self.position < 0:  # short signal\n",
    "            return -1\n",
    "        elif z_score < lower_threshold and self.position > 0:  # long signal\n",
    "            return 1\n",
    "        elif abs(z_score) < self.close_threshold and self.position == 0:  # neutral\n",
    "            return 0\n",
    "        \n",
    "        return self.position  \n",
    "    "
   ],
   "execution_count":134,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"wRhppbYI0DdPVGNLwwiDYz",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def train_multi_pair_dqn(env, episodes, active_func, batch_size=32):\n",
    "    state_size = 5  # position, spread, z-score, remaining_steps, portfolio_value\n",
    "    action_size = len(env.action_space)\n",
    "    \n",
    "    agent = DQNAgent(state_size, action_size, active_func)\n",
    "    \n",
    "    # Initialize training metrics for each pair\n",
    "    training_metrics = {\n",
    "        # 'episode_rewards': [],\n",
    "        # 'portfolio_values': [],\n",
    "        'pair_performance': {pair: {\n",
    "            'rewards': [],\n",
    "            'portfolio_values': [],\n",
    "            'best_portfolio_value': float('-inf'),\n",
    "            'best_reward': float('-inf'),\n",
    "            'best_cumulative_return':[],\n",
    "            'best_state_dict': None\n",
    "        } for pair in env.pair_list}\n",
    "    }\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        current_pair = env.current_pair\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            agent.memory.push(state, action, reward, next_state, done)\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.learn()\n",
    "            \n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "    \n",
    "        \n",
    "        # Store pair-specific metrics\n",
    "        pair_metrics = training_metrics['pair_performance'][current_pair]\n",
    "        pair_metrics['rewards'].append(episode_reward)\n",
    "        pair_metrics['portfolio_values'].append(env.portfolio_value)\n",
    "        \n",
    "        # Update best model for current pair if performance improves\n",
    "        if episode_reward > pair_metrics['best_reward']:\n",
    "            pair_metrics['best_portfolio_value'] = env.portfolio_value\n",
    "            pair_metrics['best_reward'] = episode_reward\n",
    "            pair_metrics['best_state_dict'] = agent.policy_net.state_dict()\n",
    "            pair_metrics['best_cumulative_return'] = env.cumulative_return\n",
    "            \n",
    "            # Update target network with best model\n",
    "            agent.target_net.load_state_dict(pair_metrics['best_state_dict'])\n",
    "            # print(f\"\\nNew best model found for pair {current_pair}!\")\n",
    "            # print(f\"Episode {episode}\")\n",
    "            # print(f\"Portfolio Value: {env.portfolio_value:.2f}\")\n",
    "            # print(f\"Episode Reward: {episode_reward:.2f}\")\n",
    "        \n",
    "        agent.decay_epsilon()\n",
    "\n",
    "        # Print progress every 10 episodes\n",
    "        # if episode % 10 == 0:\n",
    "            \n",
    "        #     print(f\"\\nEpisode {episode}\")\n",
    "\n",
    "            \n",
    "                        \n",
    "    # Find the best performing model across all pairs\n",
    "    best_pair = max(training_metrics['pair_performance'].items(),\n",
    "                   key=lambda x: x[1]['best_reward'])[0]\n",
    "    best_metrics = training_metrics['pair_performance'][best_pair]\n",
    "    \n",
    "    # print(f\"\\nTraining complete! Best performing pair: {best_pair}\")\n",
    "    # print(f\"Best portfolio value: {best_metrics['best_portfolio_value']:.2f}\")\n",
    "    # print(f\"Best reward: {best_metrics['best_reward']:.2f}\")\n",
    "    \n",
    "    # Set the final policy network to the best found\n",
    "    agent.policy_net.load_state_dict(best_metrics['best_state_dict'])\n",
    "    agent.target_net.load_state_dict(best_metrics['best_state_dict'])\n",
    "    \n",
    "    return agent, training_metrics\n",
    "\n",
    "def backtest(env, agent,target_pair):\n",
    "    state = env.reset(True, target_pair)\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    return env.action_history"
   ],
   "execution_count":135,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"cjEYx1zmudnros7uHxGAHx",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "def plot_cumulative_returns(dates, training_returns, pair, type):\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(dates, training_returns, label='Returns')\n",
    "    plt.title(f'Cumulative Returns for {pair[0]} and {pair[1]} in {type} set')\n",
    "    plt.xlabel('Dates')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_last_cumulative_return(dates, action_history, target_pair):\n",
    "\n",
    "    pair_actions = [action for action in action_history if action['pair'] == target_pair]\n",
    "    \n",
    "    if pair_actions:\n",
    "        last_action = pair_actions[-1]\n",
    "        cumulative_return = last_action['cumulative_return']\n",
    "        # plot_cumulative_returns(dates, cumulative_return, target_pair, 'Testing')\n",
    "        \n",
    "        mean_return, sharpe = get_summary(cumulative_return)\n",
    "\n",
    "        return {\n",
    "        'Mean Return (%) Annual': \"{:.4f}\".format(mean_return),\n",
    "        'Sharpe Ratio Annual': \"{:.4f}\".format(sharpe)\n",
    "    }\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_summary(cumulative_return):\n",
    "\n",
    "    periodic_returns = (1 + cumulative_return[1:]) \/ (1+cumulative_return[:-1]) - 1\n",
    "    periodic_returns = periodic_returns[~np.isinf(periodic_returns) & ~np.isneginf(periodic_returns)]\n",
    "    periodic_returns = periodic_returns[~np.isnan(periodic_returns)]\n",
    "    # Mean return\n",
    "    mean_return = np.mean(periodic_returns) *252 * 100\n",
    "    \n",
    "    # Sharpe ratio (assuming risk-free rate = 0)\n",
    "    sharpe = (np.mean(periodic_returns) \/ np.std(periodic_returns))* np.sqrt(252)\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative = np.array(cumulative_return)\n",
    "    running_max = np.maximum.accumulate(cumulative)\n",
    "\n",
    "    # drawdowns = (cumulative - running_max) \/ running_max\n",
    "    # drawdowns = drawdowns[~np.isnan(drawdowns)]\n",
    "    # drawdowns = drawdowns[~np.isinf(drawdowns) & ~np.isneginf(drawdowns)]\n",
    "    # max_drawdown = np.min(drawdowns) * 100  # Convert to percentage\n",
    "\n",
    "    return mean_return, sharpe#, standard_error\n"
   ],
   "execution_count":136,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"UnQLGJPYHFjp1iGgkzUbhP",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    start_year = 2014\n",
    "    end_year = 2023\n",
    "    summary_data = []\n",
    "    for year in range(start_year, end_year - 1):\n",
    "\n",
    "        yearly_mask = pd.to_datetime(tr_dm_net.index).year == year\n",
    "        yearly_plus1_mask = pd.to_datetime(tr_dm_net.index).year == year + 1\n",
    "        yearly_plus2_mask = pd.to_datetime(tr_dm_net.index).year == year + 2\n",
    "\n",
    "        formation_period = tr_dm_net[yearly_mask]\n",
    "        train_period = tr_dm_net[yearly_plus1_mask]\n",
    "        test_period = tr_dm_net[yearly_plus2_mask]\n",
    "\n",
    "        formation_period_price = tr_dm_net_price[yearly_mask]\n",
    "        train_period_price = tr_dm_net_price[yearly_plus1_mask]    \n",
    "\n",
    "        noncoherent_pairs_in_formation = noncoherent_pair_cluster(formation_period, formation_period_price)\n",
    "\n",
    "        window_size_list = [30, 60]\n",
    "        upper_threshold_list = [1.0, 1.25, 1.5,1.75]\n",
    "        close_threshold_list = [0.1, 0.2]\n",
    "\n",
    "        # upper_threshold, close_threshold, window_size = optimize_parameters(train_period, noncoherent_pairs_in_formation, window_size_list, upper_threshold_list,close_threshold_list)\n",
    "        upper_threshold = 1.0\n",
    "        close_threshold = 0.1\n",
    "        window_size = 60\n",
    "        beta = 0.1\n",
    "\n",
    "        env = MultiPairTradingEnv(train_period, noncoherent_pairs_in_formation, upper_threshold, close_threshold, window_size, beta)\n",
    "        # optimal_active_fnc = test_activations(env)\n",
    "        optimal_active_fnc = 'tanh'\n",
    "        train_agent, train_env = train_multi_pair_dqn(env, episodes=100, active_func = optimal_active_fnc)\n",
    "    \n",
    "        training_dates = train_period.index[window_size+1:]\n",
    "        for pair in noncoherent_pairs_in_formation:\n",
    "\n",
    "            best_cumulative_return = train_env['pair_performance'][pair]['best_cumulative_return']\n",
    "            # plot_cumulative_returns(training_dates, best_cumulative_return, pair, 'Training')\n",
    "            mean_return, sharpe = get_summary(best_cumulative_return)\n",
    "\n",
    "            summary_training = {'Mean Return (%) Annual': \"{:.4f}\".format(mean_return),\n",
    "                                'Sharpe Ratio Annual': \"{:.4f}\".format(sharpe)\n",
    "                                }\n",
    "            \n",
    "            summary_training['Pair'] = f\"{pair[0]}-{pair[1]}\"\n",
    "            summary_training['Data Type'] = 'Training Data'\n",
    "            summary_training['Period'] = f\"{year} - {year + 2}\"\n",
    "\n",
    "            summary_data.append(summary_training)\n",
    "\n",
    "        # Backtest\n",
    "        noncoherent_pairs_in_train = noncoherent_pair_cluster(train_period, train_period_price)\n",
    "        env_test = MultiPairTradingEnv(test_period, noncoherent_pairs_in_train, upper_threshold, close_threshold, window_size, beta)\n",
    "        testing_dates = test_period.index[window_size+1:]\n",
    "        for target_pair in noncoherent_pairs_in_train:\n",
    "\n",
    "            backtest_actions = backtest(env_test, train_agent, target_pair)\n",
    "            summary_testing = get_last_cumulative_return(testing_dates, backtest_actions, target_pair)\n",
    "            summary_testing['Pair'] = f\"{target_pair[0]}-{target_pair[1]}\"\n",
    "            summary_testing['Data Type'] = 'Test Data'\n",
    "            summary_testing['Period'] = f\"{year} - {year + 2}\"\n",
    "\n",
    "            summary_data.append(summary_testing)\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Reorder columns\n",
    "    columns = ['Data Type', 'Period', 'Pair', 'Mean Return (%) Annual', 'Sharpe Ratio Annual']\n",
    "    summary_df = summary_df[columns]\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ],
   "execution_count":140,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"h8vCuYH04ghAg6efPfuv9J",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "pivot_df = pd.pivot_table(\n",
    "   summary_df,\n",
    "   index=['Period', 'Pair'],\n",
    "   columns='Data Type',\n",
    "   values=['Mean Return (%) Annual', 'Sharpe Ratio Annual'],\n",
    "   aggfunc='first' \n",
    ").round(4)\n",
    "pivot_df.head(60)"
   ],
   "execution_count":141,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th colspan=\"2\" halign=\"left\">Mean Return (%) Annual<\/th>\n",
       "      <th colspan=\"2\" halign=\"left\">Sharpe Ratio Annual<\/th>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th><\/th>\n",
       "      <th>Data Type<\/th>\n",
       "      <th>Test Data<\/th>\n",
       "      <th>Training Data<\/th>\n",
       "      <th>Test Data<\/th>\n",
       "      <th>Training Data<\/th>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>Period<\/th>\n",
       "      <th>Pair<\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">2014 - 2016<\/th>\n",
       "      <th>GT10 Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>2.9862<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.8084<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GT10 Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>10.1757<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2.2503<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GT10 Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>3.5005<\/td>\n",
       "      <td>-4.9295<\/td>\n",
       "      <td>0.8517<\/td>\n",
       "      <td>-1.1394<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>2.9110<\/td>\n",
       "      <td>2.8007<\/td>\n",
       "      <td>0.8280<\/td>\n",
       "      <td>0.6927<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>0.0385<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.0130<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>0.2850<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.1162<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.5869<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.1461<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTITL10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.6677<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.0926<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTNZD10Y Govt Adjusted-GTJPY10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.3149<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.2833<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2015 - 2017<\/th>\n",
       "      <th>GT10 Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>-0.2669<\/td>\n",
       "      <td>2.0538<\/td>\n",
       "      <td>-0.0862<\/td>\n",
       "      <td>0.5868<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GT10 Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>3.1958<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.8232<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>2.7960<\/td>\n",
       "      <td>-0.2967<\/td>\n",
       "      <td>1.0635<\/td>\n",
       "      <td>-0.0906<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>1.3107<\/td>\n",
       "      <td>4.3133<\/td>\n",
       "      <td>0.4661<\/td>\n",
       "      <td>1.5022<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.8872<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.8488<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>-3.8088<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.4284<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTITL10Y Govt Adjusted-GTAUD10Y Govt Adjusted<\/th>\n",
       "      <td>-10.7915<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-2.3219<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTITL10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>9.7541<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2.0348<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">2016 - 2018<\/th>\n",
       "      <th>GT10 Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-2.8837<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.0757<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.2537<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.0999<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-3.9826<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.4375<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-4.7842<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.8514<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTITL10Y Govt Adjusted<\/th>\n",
       "      <td>-1.5296<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.2564<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTITL10Y Govt Adjusted-GTAUD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-6.4109<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.4047<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTITL10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2.2631<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.4381<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTNZD10Y Govt Adjusted-GTJPY10Y Govt Adjusted<\/th>\n",
       "      <td>-1.2335<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.4092<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>-2.5503<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.9434<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>-6.0246<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-2.3097<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">2017 - 2019<\/th>\n",
       "      <th>GT10 Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>-4.4216<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.0066<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCAD10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>7.0178<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.5552<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>3.1003<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.8822<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTITL10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.3757<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.0628<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTSEK10Y Govt Adjusted<\/th>\n",
       "      <td>0.0496<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.0202<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTGBP10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>1.4412<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.4054<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTNZD10Y Govt Adjusted-GTJPY10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.1982<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.4057<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.3816<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.5464<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.9101<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.3679<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">2018 - 2020<\/th>\n",
       "      <th>GT10 Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.9024<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.4354<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCAD10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>1.5661<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.5090<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCAD10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.1147<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.2459<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>-4.3108<\/td>\n",
       "      <td>-1.2426<\/td>\n",
       "      <td>-1.4126<\/td>\n",
       "      <td>-0.3670<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>2.5176<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.8604<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>-2.4177<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.8703<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTSEK10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.1793<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.4442<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTGBP10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>1.1526<\/td>\n",
       "      <td>-1.1897<\/td>\n",
       "      <td>0.2898<\/td>\n",
       "      <td>-0.3317<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTITL10Y Govt Adjusted-GTAUD10Y Govt Adjusted<\/th>\n",
       "      <td>-0.9364<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.1403<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>-4.5268<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.4127<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>4.8250<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.9746<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">2019 - 2021<\/th>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTJPY10Y Govt Adjusted<\/th>\n",
       "      <td>7.9987<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.5922<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>-5.7351<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.3419<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCAD10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.7182<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.2395<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>1.5543<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.4449<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>-5.4240<\/td>\n",
       "      <td>3.1682<\/td>\n",
       "      <td>-1.7611<\/td>\n",
       "      <td>1.0337<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>-0.9927<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.3923<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.1829<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.3705<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.8553<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.3971<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTGBP10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.8968<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.2303<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTITL10Y Govt Adjusted-GTAUD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.7043<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.1242<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTNZD10Y Govt Adjusted-GTJPY10Y Govt Adjusted<\/th>\n",
       "      <td>-0.8124<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.1940<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>-1.7910<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.5892<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>-1.0424<\/td>\n",
       "      <td>-0.8089<\/td>\n",
       "      <td>-0.3637<\/td>\n",
       "      <td>-0.2570<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{},
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"8yxiX4l4zLBPX6NKgbZWcf",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "pivot_df.tail(32)"
   ],
   "execution_count":142,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th colspan=\"2\" halign=\"left\">Mean Return (%) Annual<\/th>\n",
       "      <th colspan=\"2\" halign=\"left\">Sharpe Ratio Annual<\/th>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th><\/th>\n",
       "      <th>Data Type<\/th>\n",
       "      <th>Test Data<\/th>\n",
       "      <th>Training Data<\/th>\n",
       "      <th>Test Data<\/th>\n",
       "      <th>Training Data<\/th>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>Period<\/th>\n",
       "      <th>Pair<\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "      <th><\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">2019 - 2021<\/th>\n",
       "      <th>GTCAD10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.7182<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.2395<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>1.5543<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.4449<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>-5.4240<\/td>\n",
       "      <td>3.1682<\/td>\n",
       "      <td>-1.7611<\/td>\n",
       "      <td>1.0337<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>-0.9927<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.3923<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.1829<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.3705<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.8553<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.3971<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTGBP10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.8968<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.2303<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTITL10Y Govt Adjusted-GTAUD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.7043<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.1242<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTNZD10Y Govt Adjusted-GTJPY10Y Govt Adjusted<\/th>\n",
       "      <td>-0.8124<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.1940<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>-1.7910<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.5892<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>-1.0424<\/td>\n",
       "      <td>-0.8089<\/td>\n",
       "      <td>-0.3637<\/td>\n",
       "      <td>-0.2570<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCHF10Y Govt Adjusted<\/th>\n",
       "      <td>-2.7799<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.5925<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>2.9434<\/td>\n",
       "      <td>-1.6873<\/td>\n",
       "      <td>1.5142<\/td>\n",
       "      <td>-0.6903<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>1.4998<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.6649<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">2020 - 2022<\/th>\n",
       "      <th>GT10 Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>9.0830<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.2439<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTJPY10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>9.0278<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.9331<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTAUD10Y Govt Adjusted-GTNZD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.2932<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.2861<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCAD10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>-6.6472<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-1.1548<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>5.4053<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.6654<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.5478<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.5468<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCHF10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.6591<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.7190<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTNZD10Y Govt Adjusted-GTJPY10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>5.0598<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.3587<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>-5.8501<\/td>\n",
       "      <td>2.0755<\/td>\n",
       "      <td>-0.7873<\/td>\n",
       "      <td>0.7056<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCAD10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.2729<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.4453<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCHF10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.1241<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.6829<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.4985<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.2758<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTGBP10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.7138<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.3217<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021 - 2023<\/th>\n",
       "      <th>GT10 Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>3.6072<\/td>\n",
       "      <td>3.0667<\/td>\n",
       "      <td>0.5266<\/td>\n",
       "      <td>0.4255<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTCAD10Y Govt Adjusted-GTDEM10Y Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>1.5358<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.2420<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTFRF10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>-2.0499<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>-0.3766<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GT10 Govt Adjusted<\/th>\n",
       "      <td>NaN<\/td>\n",
       "      <td>5.6018<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.6820<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>GTSEK10Y Govt Adjusted-GTCHF10Y Govt Adjusted<\/th>\n",
       "      <td>0.6354<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>0.1335<\/td>\n",
       "      <td>NaN<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{},
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"vtc3UHb1reIhBx3cBafEGv",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[],
   "report_row_ids":[],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}